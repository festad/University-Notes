
#+title: Intelligenza Artificiale

2022-09-26

Problema a stati multipli

Nulla osservabilita'
osservabilita' parziale (robot aspirapolvere), 8
possibili stati.

Un problema di ricerca a stati multipli ha un numero di belief
esponenzialmente piu' grande del numero degli stati, e'
l'insieme delle parti, 2^(8) -1 possibili stati.

Dato un diagramma degli stati, questi stati sono raggiungibili? (e'
una possibile domanda da esame).

Formalizzare un problema:
bisogna scegliere gli stati, formalizzare le azioni.
Esempio:
Problema dei missionari e cannibali:
- stati,
- azioni:
  - precondizioni se ci sono,
  - effetti,
- stato iniziale del problema,
- stato goal (insieme di stati goal,
  in questo caso lo stato goal e' che i
  missionari e cannibali sono tutti dall'altra
  parte del fiume).
- costo della soluzione trovata.


* Algoritmo generico di ricerca

Tutti gli esempi li vedremo con uno stato
iniziale,
L e' la lista iniziale degli stati,
se L e' la foglia diremo che non
esiste soluzione al problema.
Se L non e' vuota c'e' almeno
un nodo sulla frontiera, si sceglie
un nodo foglia (potrebbe anche essere random,
lo scegliamo dopo), dopodiche' controlliamo
se e' foglia e soddisfa il gol test,
se lo soddisfa allora riscriviamo n e
il cammino da nodo ad n,
perche' restituiamo n? perche' a volte
lo stato gol non e' noto (es provlema
delle n regine),
se il gol test non si applica viene eseguita
l'istruzione successiva (che non viene eseguita
se il gol test non ha successo),
tiriamo via n da L (lo abbiamo appena visitato)
e gli aggiungiamo i figli di n, n non e'
piu' una frontiera ma ci aggiungiamo i suoi figli,
come? quali? per il momento tutti, poi vediamo.
Ls strategia di ricerca determina come si costruisce
l'albero di ricerca, ci sono quelle
cieche o non informate che scelgono il nodo
dalla frontiera solo in base alla posizione nell'albero,
quelle euristiche o informate scelgono il nodo promettente
dalla frontiera usando informazioni esterne che c'entrano
parzialmente con la posizione nell'albero.
Un esempio di euristica e' il numero
di caselle fuori posto nel problema del piazzamento
dei numeri nel sudoku.

* Tecniche euristiche

2022-10-04
Best-first search

h*(n) = reale distanza di n dal gol piu' vicino (ci potrebbero
essere piu' stati che garantiscono il gol),
quando h(n) e' ammissibile l'algoritmo si chiama A*,
A per ammissibile, * indica che trova sempre la soluzione ottima.


Confronto tra euristiche:
ci sono due metodi per confrontare le euristiche a coppie:
il confronto teorico e il confronto sperimentale o empirico.

Confronto teorico: e' piu' difficile, richiede matematica pesante,
si deve dimostrare che per ogni stato l'euristica di un nodo
e' minore o uguale dell'euristica dell'altro, a patto
che entrambe le euristiche siano ammissibili.
Se h1(n)<=h2(n) per ogni n allora h2 e' migliore,
ma dipende dal problema e dalle euristiche.

Metodo sperimentale: molto utilizzato.
Bisogna scrivere un'equazione,
prendiamo tanti problemi (configurazione
iniziale random e finale fissa), risolvo tanti problemi
usando un'euristica e tanti usando un'altra,
quando risolvo un problema posso o considerare il cpu time
(ma non e' furbo) oppure posso contare il numero di nodi visitati,
chiamiamo N il numero di nodi generati da A* in un run (anche nodi
generati si puo' dire invece che visitati), poi si tiene traccia
durante la soluzione della profondita' dove si trova il nodo gol,
equazione: ...

Confronto tra l'euristica di manhattan,
confronto delle euristiche con il metodo sperimentale con la
costruzione dell'albero fittizio per vedere b*.

Nuovo algoritmo:

Iterative deepening

Una possibilita', simile a quella della ricerca cieca non informata
in profondita, ripetiamo una ricerca in A* dando un bound sulla
lunghezza della soluzione che stiamo cercando,
iterative deepening A*,
diamo un limite alla lunghezza del cammino che viene
incrementato iterativamente.
Dobbiamo capire il taglio,
potrei pero' ripetere piu' volte la stessa cosa,
scegliamo come cut g(n), perche' gli archi
non hanno costo unitario ma costo definito da g,

Con l'incremento di uno, se ripeto la ricerca e' garantito
che visito almeno un nodo in piu'.

Seminario: A* con tecniche ulteriori.
come lavorare sulla lista L, usando qualcosa in piu' della f
allo scopo di risparmiare memoria.

Parliamo di un'altra classe di tecniche.

** Tecniche di ricerca locale

hill climbing, funzione da massimizzare,
anche se noi h la minimizzavamo prima,
no problem, mettiamo il meno davanti e manteniamo
la regola di massimizzare invece che minimizzare,
l'algoritmo si chiama discesa del gradiente.

Non costruiamo piu' l'albero di ricerca,
invece di inserire i figli nella lista L si
sceglie un figlio (se l'euristica e' furba
sceglie la mossa giusta da fare, senno' sceglie
quello sbagliato),
scegliamo il migliore,
ovvero quello con h piu' basso (ho meno
lavoro da fare),
l'hill climbing pero' era stato formulato
come problema di massimizzazione,
sceglieva h maggiore,
si puo' pero' riformulare in maniera
duale l'euristica,
in genere si usa h da minimizzare in AI,
la distanza di Manhattan e' difficile da riformulare
una volta scelto il figlio si cancella il padre e tutti gli altri figli.
si fa una scelta vincolante che non permette di tornare indietro,

Tecniche dell'hill climbing + euristiche

*** Mosse laterali
Se non riesci a uscire dalla pianura migliorando ricmoincia da capo.

*** Stocastico a: con probabilita' per stati successori
Il prossimo passo non e' deterministico e univoco
ma e' un range di possibili operazioni
scelte con una probabilita',
quando si arriva al momento non deterministico si tira
una moneta sbilanciata, piu' esecuzioni possono essere
diverse a parita' di input.
Lo faccio perche' l'euristica ogni tanto sbaglia,
per compensare non la seguo sempre ma ogni tanto
faccio qualcosa di diverso da quello che mi dice.
 
*** Stocastico b con prima scelta migliorativa random


*** stocastico c con riavvii casuali _ mosse laterali


*** Simulated annealing


*** Ricerca locale Local Beam

Si puo' inserire la randomizzazione anche qui,
si scelgono anche
dei K che peggiorino

*** Tabu Search

Senza run paralleli, si introduce un po' di memoria
a Climb Hill, si memorizzano gli ultimi K stati
visitati o le ultime K azioni,
puo' evitarci dei loop,
sono tecniche che si prestano a spazi
di ricerca molto grandi, non voglio
avere un algoritmo che visita pochi stati,
devo avere un algoritmo che visita tanto
perche' lo spazio e' immenso e allo
stesso tempo abbia memoria sufficiente a
evitare dei loop, es K 10, 20, 100..
dipende dal problema specifico.
Se k passi sono sufficienti a uscire
dal minimo locale allora si puo' raggiungere il
minimo assoluto, senno' si rimane ancora
intrappolati nel minimo locale.

*** Enforced Hill-Climbing
Per ogni stato visitato usa una ricerca
in ampiezza per trovare un discendente
di S che abbia valore euristico
migliore di S.
Si ferma sul primo che trova migliorativo.

Trovato il nodo che migliora si butta via il resto,
si riparte dallo stato corrente, si controllano i successori.
Queste tecnica la ritroveremo perche' e' stata usata in un
sistema di pianificazione automatico con un'euristica macchina,
H si puo' calcolare automaticamente senza conoscere
il dominio del problema.

Se S e' un minimo locale molto profondo
serve una ricerca in ampiezza molto profonda,
il problema della ricerca locale e' legato
a come e' fatta la funzione euristica rispetto
agli stati del problema.

Se volessimo minimizzare la funzione
e mi trovassi in un minimo locale
i successori sarebbero peggiorativi,
se voglio uscire dal minimo locale
pero' devo scrivere un albero abbastanza
profondo, tanto quanto sono le azioni
necessarie a raggiungere un successore
migliorativo,
servira' una profondita' dell'albero elevata,
questa tecnica puo' non funzionare quando h
ha minimi locali profondi, e la memoria
si esaurirebbe nel migliore dei casi.

*** Algoritmi genetici
Con risultati misti, a volte funziona
e a volte e' disastrosa, richiama l'evoluzione
della popolazione di generazione in generazione,
nel processo evolutivo c'e' un miglioramento della specie.

Gli algoritmi genetici richiedono che uno stato
sia rappresentato con una stringa di numeri (elementi,
vettore),
nel problema delle 8 regine potrebbe essere
[riga della regina in colonna 1, riga della regina in colonna 2, ...].
Devo partire da un insieme di stati che rappresentano la popolazione,
faccio un processo evolutivo nel tentativo di trovare
un individuo che soddisfa il problema,
es l'assenza di attacchi tra regine.

Posso disporre le regine casualmente,
il problema del rompicapo dell-8 uguale, potrei iniziare con
posizioni casuali.

Determinata la posizione iniziale si fa una valutazione
euristica degli individui della popolazione,
negli algoritmi genetici l'euristica si chiama
funzione di fitness,
a questo punto selezioniamo dalla popolazione individui da accoppiare,
si scelgono sulla base della funzione euristica e in maniera stocastica,
chi ha una funzione euristica migliore deve avere piu' probabilita' di
essere scelto,
come si genera lo stato successore a partire da due stati?
Si mescolano le caratteristiche,
ci possono essere varie strategie, per es prendere un po' di piu' da chi
ha la funzione euristica piu' alta.

*** Algoritmo con ricerca online

Non ha senso pensare a tutta la soluzione,
potrebbe succedere che non ho tempo per pensare alla soluzione,
devo fare qualcosa in un secondo,
puo' essere necessaria la ricerca online
perche' il mondo non e' statico,
ho conoscenza parziale dell'ambiente e anche
delle mie azioni,
non posso costruire una soluzione che funzioni
sempre allo stesso modo,
la prossima azione da fare viene prima
calcolata e poi eseguita,
dopodiche' la gente deve osservare lo stato:
ci sono due casi:
- il mondo e' totalmente accessibile,
  l'agente sa com'e' l'ambiente dopo che
  ha effettuato l'azione,
- il mondo e' parzialmente accessibile

L'azione puo' avere costi diversi a seconda
dello stato che ha generato,
ma non sappiamo all'inizio quali sono gli effetti,
delle azioni,
le precondizioni delle azioni le conosciamo
ma scopriremo gli effetti delle azioni solo
dopo averle eseguite,
inoltre la funzione gol test decide se uno stato
e' gol o no.

Anche gli stati successori si conoscono solo
dopo aver eseguito tutte le azioni applicabili
nello stato, c'e' dell'apprendimento,
scopriro' come e' fatto il diagramma degli stati,
non lo so a priori.
Pero' ho la totale osservabilita', imparero' gli
effetti dell'azione, so sempre dove sono andato
a finire dopo aver compiuto l'azione.
Dopo aver eseguito l'azione imparo il suo costo e
il suo effetto.

La ricerca in ampiezza non puo' essere resa online
La ricerca in profondita' puo' essere
resa online perche' la ricerca avviene di pari
passo con la valutazione,
posso spostarmi in uno stato e man mano che
scendo eseguo anche l'azione che mi fa scendere,
l'unico problema e' quando
arrivo in fondo, ovvero trovo un vicolo cieco,
quindi quando arrivo in fondo?
Devo aver inserito una regola, l'azione
che fa tornare indietro,
l'azione di reverse che riporta al padre,
una volta tornato al padre posso chiedermi
se ha altri figli,

2022-10-11

Algoritmi di ricerca online,
concetto di backtracking,
vuol dire tornare indietro in un punto della ricerca,
quando siamo arrivati a un nodo senza successori si fa
backtracking,
oppure quando uno stato e' nella closed list
e si evita di rivisitarlo,

** Ricerca in profondita' online

result e' inizialmente vuoto e rappresenta
gli effetti delle azioni,
inizialmente l'algoritmo non sa nulla,

unexplored e' una tabella
che lista per ogni stato quali sono le
azioni che non si sono ancora provate
ad applicare,
unbacktracked: tiene traccia di tutti
i possibili punti di ritorno della ricerca,

ad ogni run abbiamo mmeoria dell'ultimo stato (precedente),
l'ultima azione eseguita (+ le tre variabili globali,
result, unexplored e unbacktracked).

Pseudocodice:
le azioni disponibili in uno stato sono statiche,
si sanno sin dall'inizio e non cambiano,
se s=0 allora s==s',
aggiungo s alla lista degli unbacktracked quando
da s mi sposto a s',
se e' la prima volta che entro in s' ho la lista
di tutte le azioni da eseugire,
se invece ci ero gia' passato
la lista unexplored[] potrebbe non essere
vuota perche' ho gia' provato qualcosa,
quindi prendo un'azione (la prima) disponibile
in unbacktracked (la prima perche' facciamo ricerca in
profondita') e aggiorno lo stato vecchio che non sara'
piu' s ma s', lo stato corrente in cui sono,
return a fa eseguire a,
nel caso in cui non abbiamo piu' azioni da esplorare
vediamo se c'e' un punto indietro che abbia una strada
aperta (potrebbe anche non esserci, per es. se il problema non
ha soluzione), se non c'e' ritorno fallimento,

es pg 69
terza iterazione
S = B
S; = C
unexp[C] = (03)
unback[C] = (B)
Q = 03
unexp[C] = ()

S' NON e' un nuovo stato

S = C
S'= A
non tocco unexplored
unexplored[A] e' vuoto
unback[A] e' vuoto?
unbac[A] = C

e' un algoritmo corretto e completo,
e' un algoritmo che sa fermarsi e riconoscere
che non c'e' soluzione pur essendo
a parziale conoscenza,
ma con l'assunzione che abbia totale osservabilita',
inoltre ha una complessita' limitata, infatti
ogni arco viene visitato al piu' due volte,
il numero di chiamate resta polinomiale,
le azioni di reverse sono necessarie,
quindi gli archi devono essere bidirezinoali,
ci sono anche altri algoritmi online senza
questa assunziuone ma potrebbero non trovare la soluzione.

actions[] contiene solo le azioni normali,
non quelle di reverse o backtracking


** Random walk

ricerca locale online,

in ciascun nodo ho una possibilita' per progredire
e due per regredire,
da questo diagramma si evince che se mi muovo
in modo casuale ho una doppia probabilita'
di peggiorare rispetto a quella di migliorare,


pg. 73,
Conosciamo h(s) della funzione euristica,
conosciamo i valori euristici per ogni stato,
inizialmente siamo a meta' della catena bidirezionale,

** LRTA*-Agent

Ripetendo l'algoritmo tante volte si riesce
a trovare la soluzione ottima ma non la prima
volta, la funzione euristica h viene
aggiornata ogni volta,


* Constraint Satisfaction Problems

** Map-coloring

Gli stati che soddisfano il gol test si chiamano soluzioni,
non siamo interessati ai passi per raggiungere la
soluzione ma a trovare una soluzione,
vogliamo trovare uno stato che soddisfi il gol test.

Il csp, nel caso di vincoli binari, puo' essere
modellizzato con un grafo.
La Tazmania non ha vincoli, non e' collegata a niente,
la semantica degli archi puo' significare diverse
cose a seconda del problema,
qui significano un vincolo della diversita' dei colori,

ad occhio si vede (slide 6) che il grafo
non e' connesso, posso decomporre il problema
in sottoproblemi uno diverso dall'altro,
riducendo la complessita' del problema originale.

Nel sudoku ci sono 9^{81} stati possibili,
i vincoli sono quelli del problema:

i vincoli binari sono preferiti.
Per ogni riga: $\frac{9^2-9}{2}=36$ vincoli,
il numero totale di vincoli e' (36*9*3),
il grafo e' sparso perche' il numero degli archi sarebbe
$\frac{81^{2}-81}{2}=3240$, molti di piu'.

Nel problema delle 8 regine
ci sono 8^8 possibili configurazioni,
i vincoli sono $\frac{8^2-8}{2}=28$ e tutti uguali,
anche il problema delle regine e' formalizzato come
un CSP.

** Backtracking search

Un valore viene assegnato solo se non e' in conflitto
con gli altri a differenza di prima,
il gol test si applica in modo incrementale.

Per ogni valore x in X deve esistere un valore y nel
dominio della variabile y,
se non e' vero x viene tolto dal dominio di X.


** Arc consistency

20221018


n -> numero di variabili
d -> cardinalita' del numero delle variabili

In input c'e' il csp, ogni variabile ha il suo dominio,
inizialmente mettiamo tutti gli archi del csp,
nel grafo c'e' un arco per ogni coppia di variabili,
gli archi sono bidirezionali,
se c'e' un vincolo di diversita' tra x e y
dovremo mettere (x,y) e (y,x) nella coda,
la coda viene processata finche' diventa vuota,
poi prendo il primo elemento e forzo la consistenza
tra le due variabili selezionate,
forzare la consistenza si fa con la funzione RM-INCONSISTENT-VALUES(X_i, X_j),
poi faccio il controllo della proprieta' di consistenza,
se non c'e' vincolo tra la coppia allora il check e'
automaticamente soddisfatto,
se ho modificato il dominio di x_i potrebbe esserci
un'altra variabile x_j per cui non vale il vincolo
di consistenza,
devo inserire tutte le coppie per fare nuovamente il check.

Esempio:
x_i -> x_j

nel fare il controllo modifico il dominio di x_i,
quindi prendo tutte le x_k nel vicinato di x_i,
[x_k1, x_k2, x_k3..] che hanno un vincolo con x_i,
potrei anche metterle tutte ma sprecherei risorse,
metto solo quelle nel neighborood,
Neighbor[x_i],
si inseriscono tutte nella coda perche'
ora che x_i e' cambiato il controllo fatto
prima potrebbe non essere piu' valido,
prima dicevamo che in x_i c'era almeno un
valore nel dominio che era != da x_j,
es x_i = {3,9},
x_k1 = {3,7},
se tolgo il 9 x_k1 e x_i non soddisfano piu'
il vincolo di diversita'.

L'algoritmo termina?
Tolgo ma aggiungo anche elementi nella coda, magari
non si svuota mai...
in realta' si svuota perche' le coppie sono finite
e la stessa coppia puo' entrare nella coda un numero
finito di volte,
al massimo tante quante posso cambiare il dominio
della variabile (che ogni volta che cambia puo'
diventare piu' piccolo ma mai piu' grande),
le coppie del vicinato rientrano nella queue
un numero massimo pari alla cardinalita' dei domini.

L'algoritmo termina perche' una coppia entra in queue
al massimo d volte (d=max numero di elementi in una variabile),

Costo: O(n^2d^3),

all'interno del while eseguiamo un d^2,
dobbiamo contare le coppie dei nodi che entrano
nella queue nel caso peggiore,
inizialmente le coppie sono n^2-n, O(n^2),
per ogni ciclo devo eseguire un algoritmo che costa
d^2,
O(n^2)*O(d^2),
la stessa coppia puo' rientrare nella queue al massimo
d volte,
quindi n^2*d*d^2,

si pou' fare pruning dei valori,
e' una forma di inferenza potente nell'algoritmo di
backtracking.
Nel fare l'arc consistency i valori possono essere
eliminati.

** Backtracking with inference

Viene chiamato il backtrack (ricorsivo) e controlliamo
alla fine della ricorsione se l'assegnamento e' completo,
il check di consistenza dei vincoli e' fatto man mano
che assegno valori alle variabili,
prendo una variabile (the most constraining variable)
e provo tutti i possibili valori, correntemente nel dominio,
se il valore e' consistente con l'assegnamneto allora
incremento l'assegnamento col nuovo assegnamento a var,
dopodiche' applico l'arc consistency,
la applico al csp modificato,
alcune variabili hanno valore fisso,
il csp e' dinamico,
altre variabili potrebbero avere
un dominio ristretto,
se non c'e' fallimento aggiungo alle inferenze
che ho fatto faccio un assegnamento nullo,
dopodiche' faccio backtracking sulle variabili
che rimangono da assegnare,
es. esercizio dei sudoku,
abbiamo valori settati inizialmente,

3-consistenza = path-consistenza,
eliminare le coppie che non soddisfano la
proprieta', per rendere il vincolo piu'
restrittivo,

il problema alla lavagna e' arc consistente
ma non path consistente (no alla coppia 2,2, perche'
2<=2<2 non e' vero.

La ricerca locale per i CSP
non e' completa, non puo' accorgersi
di aver considerato tutto e di poter
terminare la ricerca,
non si ha la garanzia di aver
visitato tutto,
si parte invece che da un assegnamento
vuoto come nel backtracking, da un assegnamento
aleatorio e si controlla se e' una soluzione,
se non lo e' si inserisce una perturbazione
con un numero limitato di possibilita',
si prende una variabile scelta in modo casuale
ma tra quelle che hanno valore corrente in conflitto
con quello di qualche altra variabile,
se il csp non e' una soluzione c'e' almeno un conflitto,
dopodiche' si vede come cambiare valore,
es euristica del min conflict,
si sceglie un valore che porta a ridurre il numero
di constraints violati,
oppure invece che minimizzare i conflitti si
massimizzano gli assegnamenti leciti.
Se stiamo massimizzando la nostra euristica: hill climbing,
altrimenti gradient descent.

* Seminario su $A^{\star}$

Se h e' ammissibile allora troviamo l'ottima,
ma potrebbe anche essere troppo costoso trovare l'ottimo,
allora puo' essere tollerabile trovare sol subottime, implementiamo
quindi h non ammissibile.
Ci sono soluzioni subottime con limiti, non troppo distanti
dall'ottimo, con un bound (es al massimo 3 volte peggio
dell'ottimo),
Vediamo tecniche che vanno in contro a questa esigenza.

- any solution: una sol qualsiasi
  senza garanzia sulla qualita;,
  greedy best first search (guardano solo
  h),

- bounded subottimal search: voglio
  trovare una sol : il costo e' minore di b*sol_ottima,
  se b=1 cerco l'ottimo,
  una sol e' b-ammissibile se soddisfa
  tale ugualianza,

- bounded cost search, trovare
  una sol tale che cost<=C,


** BSS - FOCAL Search

Ci si focalizza su certi elementi della open list (frontiera),
la focal list e' fatta da un sottoinsieme della open list,
devo avere una euristica h ammissibile,
(es. numero di caselle malposte, manhattan),
viene mantenuta la lista di sottoinsiemi (focal),
in cui metto gli elementi tali che $f(n) (=g(n)(=h(n)) <= \mbox{ il miglior nodo}$,
quando prendo un nodo dalla lista L non prendo piu' il nodo migliore in base
a L ma mi concentro solo sugli elementi in FOCAL, perche' contiene gli elementi
che soddisfano il requisito che voglio (quello di <=).

(Pearl - Heuristic search),
si sceglie il nodo, lo si toglie sia dalla focal sia dalla L,
se best soddisfa il gol test lo ritorno,
se f_min e' cresciuto allora fix_local,
siccome la open cambia la L, puo' anche cambiare il valore
minimo di f dei nodi nella open list,
se ho 10 nodi puo' essere che il nodo minore sia 5,
dopodiche' potrebbe diventare 4,
se cambia il valore di f_min, se e' cresciuto, allora
aggiorna il contenuto della focal list,
perche' tiene tutti i nodi che hanno f <= b*f_min,
$f(n) \leq Bf_{{min}$,
se decresce non modifico perche' non devo aggiungere
niente,
i neighbors sono i successori di best,
li aggiungo alla open list, se soddisfano
il requisito <= li aggiorno anche alla focal,
quando prelevo un nodo da espandere
lo prendo da focal e non da open,
in questo modo riesco a dimostrare che
trovo una soluzione subottima ma bounded con
il vincolo di B desiderato,

** BSS Weighted A^\star
Se w = 1 e h ammissibile troveremo la sol ottima,
g_n e' il miglior cammino conosciuto per raggiungere
n,
w tipicamente non e' < 0 ma e' >=1,
se w=1 siamo in a*,
se w > 1 abbiamo un regime diverso,
diventa stra dominante il secondo termine,
greedy best first search,
per i w non troppo grandi non trovo
la soluzione ottima perche'
se w e' 1.2 potrebbe essere che 1.2 * h non sia
piu' ammissibile,
potrei raggiungere un gol non ottimo,
pero' sto dando piu' peso all'h,
e se e' progettata bene mi aiuta a trovare
un nodo gol,
mi sto dimenticando di g (quanto mi occorre
per arrivare a quel nodo li'),
si puo' dimostrare che c'e' corrispondenza
tra weighted e focal, perche' w a* e' un
caso speciale della focal, permette di trovare
soluzioni w-ammissibili (B=w),
sono di costo peggiorativo non piu' di w le soluzioni trovate.

(Vediamo anche metodi per combinare piu' euristiche)

BSS e' una best first search con
f(n) = g(n)+W*h(n),
costo per arrivare dalla radice a n + euristica (ammissibile
o non) pesata (W),
se h e' ammissibile con W=1 abbiamo A*,
se e' > 1 l'euristica complessibile
potrebbe non essere ammissibile,
se W e' molto grande la componente g non ha
piu' nessun ruolo (viene mangiata),
quindi con W grande e' la greedy best first search,
guarda in avanti senza ricordarsi del costo gia' speso.

FOCAL: soluzioni b ammissibili,
si possono trovare soluzioni W ammissibili con BSS,
W -> costo della soluzione ottima.

** BSS Explicit estimation search (ESS),
bounded subottimal search,
trova soluzioni che hanno la garanzia di un bound
peggiorativo rispetto all'ottimo, ma non la soluzione ottima,
in questo framework c'e' l'ESS, un'altra tecnica (come FOCAL e l'altra),
abbiamo 3 euristiche da specificare:
- euristica ammissibile h, vogliamo sia ammissibile,
  chiamata cost-to-go, 
- $\hat{A}$, cost-to-go NON ammissibile, piu' aggressiva, meno
  cautelativa, osa di piu', cerca di avvicinarsi di piu'
  e potrebbe anche sbagliare,
  potrebbe essere non il numero delle azioni (azioni non unitarie),
  
- distance-to-go, anche questa non ammissibile,
  conta quante azioni servono per arrivare al gol,
  a differenza del precedente, (es. costo delle azioni
  per arrivare al gol, 5+7+9, sono 3 azioni,
  la dtg conta il 3, la ctg conta 5+7+9).

h(n) e' l'unica ammissibile per forza.

Scegliamo con una combinazione di possibilita' come
combinarle nell'algoritmo,
f, \hat{f}, d (elemento greedy, guarda in avanti, conta le azioni
per arrivare al nodo gol piu' vicino),
durante la ricerca si tiene traccia dei nodi importanti:
nella lista L valutiamo i nodi in base \hat{f} e \hat{d},
la seconda non la fa A*, la terza dice "considera tutti
i nodi nella lista open tali per cui \hat{f}(n) deve essere
<= b*\hat{f}(best_f)",
per tutti i peggiorativi al massimo b rispetto a fhat considera
quello piu' vicino al gol,
ad ogni espansione di nodo viene scelto dalla lista open
il nodo migliore secondo questo criterio:
se il meglio rispetto a fhat (non ammissibile) e' <= b*f(best)
allora scegli questo,
considero il miglior nodo che verrebbe preso da A* (prima euristica),
moltiplico il valore scelto da A* per b, se il miglior
nodo seguendo l'euristica non amm e' <= b*valore scelto da A*
allora scelgo quello con l'euristica cattiva (fhat), altrimenti
scelgo quello che avrebbe scelto A* (prima euristica, f),
prima si considera la terza euristica e se non va
scelgo il secondo criterio e lo confronto con quello che farebbe
A*,
in ultima istanza fai quello che farebbe A*,
A* garantisce l'ottimo ma ci mette tanto tempo,
le altre euristiche ci portano a un gol piu' velocemente
perche' usano euristiche piu' cattive,
con la disuguaglianza rimaniamo dentro al bound,

**BCS - Potential search,
abbiamo in input un costo C, espande i nodi
secondo la probabilita' che questi siano parte
di un piano avente costo <= C,
mi confronto con C quando sono nel nodo n,
uso la formula $u(n)=\frac{C-g(n)}{h(n)}$,
a parita' di eutistica (g<=c, tutti nodi
con costo inferiore a c),
(sin dall'inizio diciamo che c'e' una soluzione con costo C,
adesso pero' la devi trovare),
h(n) e' un'euristica,
a parita' di euristica scegliamo il nodo con g(n) piu'
piccolo e a parita di g(n) scegliamo quello con euristica
minima,
guidiamo la ricerca tenendo conto di C e privilegiando
i nodi rispetto alla funzione potenziale.
C e' dato in input ma puo' anche essere calcolato
dinamicamente considerando il nodo con l'f piu'
basso in quel momento, al posto di C che e' il nodo
della soluzione mettiamo b*f_min,
in questo modo usiamo una dynamic potential search,
quale sia meglio dipende dal problema.

L'anytime search la saltiamo, facciamo solo la definizione.
Gli algoritmi anytime producono iterativamente
soluzioni una dopo l'altra, una prodotta e'
in genere meglio delle precedenti,
sono soluzioni diverse,
si guarda non tanto la qualita' ma la diversita',
come si fa?
Versione ovvia: continuare la ricerca,
quando trovo una sol con un' h non ammissibile
allora (sol non ottima) aspetto che arrivi un'altra
soluzione, la lista L conterra' altri nodi
e vado avanti con la ricerca,
termino quando L e' vuota,
quando trovo la prima sol quella mi da'
un bound sulla qualita' della soluzione,
vado avanti e se trovo una sol con costo migliore
la fornisco in output altrimenti se ne trovo
una a costo 99 la do',
non so mai se la sol che do e' ottima ma
l'ultima che do' in output (non l'ultima trovata)
sara' migliore della precedente,
garantisce l'ottimo anche se h e' inammissibile
ma devo esplorare tutto l'albero di ricerca.
Ci sono tecniche di search che man mano trovano
una sol modificano l'euristica (non proseguono
come prima) ma cambiano l'euristica affinche'
la ricerca non porti a sol di cattiva qualita',
repairing search,
poi c'e' la restarting search,
ogni volta riparto da capo modificando il problema
per assicurarmi di non trovare soluzioni
di qualita' peggiore.

Facciamo la tecnica per la gestione delle stime (soft-bound),
l'ultima,
supponiamo di avere una stima di quanto costa
la sol, intuitivamente e ' ragionevole perche'
anche nei preventivi per organizzare un viaggio
uno si fa' un'idea di quanto spendera',
ma e' solo una stima,
supponiamo di avere un bound soft,
si possono prendere problemi
come il rompicapo dell'8 risolti,
un algoritmo di machine learning
puo' imparare a stimare i costi,
i passi per risolvere un problema di ricerca,
supponiamo di avere il bound,
possiamo usarlo per aiutare la ricerca?
iniziamo con bfs, una ricerca chiamata
hsearch non ammissibile, una h ammissibile e C,
usiamo la versione di algoritmo del W A*,
la funzione euristica di WA* tiene conto sia
di g che ti C e h_search..
questo h_bound (l'euristica che inventiamo),
e' definita prendendo l'euristica non ammissibile
e la moltiplichiamo per un fattore moltiplicativo
formato da c diviso (il conto che farebbe A*, h_delta(n)),
h_search non e' ammissibile,
viene modificata aumentandola o decrementandola in base al fattore,
se siamo molto sotto C la frazione diventa piu' grande,
se siamo sopra C stiamo andando oltre e h_search viene
penalizzata dalla frazione che diventa piu' piccola,
se i nodi hanno la componente molto minore
di c sono penalizzati,
voglio trovare la sol che costa C,
non perderti sui nodi che hanno la f troppo bassa,
perche' li sotto non c'e' la soluzione, i nodi >= C
sono piu' probabili da trovarci la soluzione se si parte
da li',
succede che se C che adotto come stima,
se il budget e' alto e posso usare tanti soldi e' piu' facile
trovare la soluzione,
se C e' vicino a quello ottimo rischiamo
di seguire troppo A* e fare troppa fatica,
se invece C non e' vicino all'ottimo
sara' piu' facile da trovare,
andrebbe un po' esagerato il costo C
se il nostro obiettivo e' trovare una sol (non
per forza la migliore),
cosi' la scelta viene nuovamente modulata
cercando di spegnere gradualmente il fattore
che moltiplica h_search,
lo facciamo con un esponente (1-p_rate)
che diventera' 1 quando il p_rate diventera' 1,
confrontiamo il n di nodi espandi dalla ricerca
con il numero di nodi espansi tali che g(n)+h(n) e' superiore
a c,
quando questo numero tende a 1 stiamo facendo troppa ricerca visitando nodi
che sono soluzioni piu' costose di c,
se g(n)+h_delta>c vuol dire che attraverso n
trovero' una sol piu' grande di c (perche' h_delta e' ammissibile),
se sono gia' molto avanti con la ricerca
e ho esplorato molti nodi oltre a c allora i due numeri
tendono a essere uguali (rapporto -> 1),
l'obiettivo e' velocizzare la ricerca,
voglio arrivare il prima possibile a una soluzione,
concentrandomi su nodi vicini a c (inutile
spendere tempo su percorsi piu' brevi, voglio
andare dove c'e' la sol a costo c, senza tentare
di risparmiare perdendo tempo).


* Test intermedio

Rimane tutto uguale a parte il seminario.
Potrebbero esserci domande sulla definizione
dei vari agenti,
semplici, stato e mondo, con gol e utilita',
gli ambienti in cui opera, deterministici,
con osservabilita' parziale.. diagramma degli
stati che diventa diagramma dei belief.

1 Es del robot aspirapolvere,
problemi con contingenze,
effetti non deterministici,
es che quando aspiro in una locazione
pulita potrebbe far cadere dello sporco,
se sono in uno stato che non ha sporco
non devo aspirare o potrei sporcare,

2 descrivere la complessita' computazionale
dell'algoritmo a approfondimento iterativo,
complessita' temporale,

Evitare cicli:
nella lista open n1 e n2 sono lo stato,
dentro ci deve essere il percorso dalla radice a n1,
ci deve essere un percorso alla radice,
se prendo n1 e non soddisfa il gol test, genero
il figlio e controllo che il figlio
non sia sul cammino che dalla radice
conduce al padre altrimenti sarebbe un ciclo:
[radice] --> ((figlio)) -->  [padre] ---> [figlio]
                 ^                            |
                 |                            |
                  ----------------------------

Formula del simulated annealing,

la funzione consistente garantisce di trovare una sol ottima
e c'e' la proprieta' di monotonicita' per cui se
incontro un nodo che ho gia' incontrato
sono sicuro che lo sto incontrando attraverso
un percorso che non e' migliore del precedente,
quindi non procedo piu' perche' quello nuovo
e' peggiorativo,
se A* e' equipaggiato da una lista di nodi chiusa
e l'euristica e' consistente se incontro
un nodo nella closed list so che il percorso
nuovo non e' migliore del precedente, faccio
pruning e non aggiungo il nodo alla open list,
se l'euristica e' solo ammissibile dovrei,
se non voglio aggiungere nuovamente il nodo,
fare il controllo che il percorso sia effettivamente
peggiore di quello trovato prima, il che non e' detto,
quindi nella open list devo scrivere anche i costi
del percorso migliore trovato per raggiungere lo
stato dalla radice.

7 descrivere almeno una delle seguenti
tecniche in hill climbing (mosse laterali o prima scelta),

- prima scelta: il vicinato (stati successori) valutali,
  comincia dal primo, confrontalo col corrente, e' migliorativo?
  no, continua, il prossimo e' migliorativo? si, acecttalo,
  mentre hill climbing li valuta tutti,
  e' utile quando ci sono tanti figli, 
- mosse laterali: anche se nel vicinato
  non c'e' nulla di meglio e ti fermeresti, cerca
  comunque (sei in una pianura) vai avanti lo stesso
  e scegli elemento con la stessa qualita',
  e' utile perche' si spera che la pianura  non sia vasta
  e e' abbastanza piccola da migliorare con poche
  mosse laterali.

8 differenza in formulazione di problema offline e online,
perche' l'online funziona solo con azioni reversibili
(dfs), il problema offline consente
di trovare l'intera soluzione prima di effettuarne l'esecuzione,
in quella online devo trovare la prossima azione, eseguirla,
abbiamo molta meno conoscenza,
nel problema online non sappiamo gli effetti delle azioni,
gli effetti delle azioni si sanno solo dopo averli eseguiti,
il diagramma delle azioni non e' potenzialmente esplicitabile
come nel caso offline prima di eseguire le azioni,
le azioni devono essere reversibili altrimenti non posso
implementare la dfs con backtracking,

9 tecnica del forward checking (con esempio per illustrare),
ogni volta che associo a x un valore v  vado a vedere
per tutte le altre variabili y legate con un vincolo
ad x se nel dominio delle variabili y c'e' qualche
valore in conflitto con v dato a x,
se il vincolo e' != e instanzio x con 1 controllo le y,
il check e' sui domini delle variabili non istanziate,
si rimuovono dal dominio i valori che creerebbero
conflitti.

20221026

* Rappresentazione della conoscenza

I CSP sono un linguaggio che rappresenta una conoscenza,
sono dotati di un linguaggio sintattico,
rappresentiamo qualcosa di vero nel mondo,
la semantica sara' legata a qualcosa
di vero,
inizialmente abbiamo formule che corrispondono a qualcosa
nel mondo reale, poi voglio che le nuove
formule rappresentino qualcos'altro che sia una conseguenza
logica delle formule originarie,
entails = implica,
follows = conseguenza (logico, semantico) (entails, sintattico),
una procedura di inferenza e' un algoritmo
che deriva nuove frasi da frasi iniziali,
puo' essere corretto, completo, tutti e due,
corretto (sound) = per ogni formula derivata, l'insieme di formule iniziali
e' chiamato knowledge base,
per ogni formula phi derivata dall'algoritmo, phi deve
essere una conseguenza logica (liv semantico) della knowledge base,
e' completo se vale il viceversa,
proof theory: e' relativa a un particolare linguaggio,
(es logica proposizionale),
la teoria della dimostrazione specifica un insieme
di passaggi che sono corretti,
i passi di inferenza sono le operazioni dell'algoritmo
che fa inferenza,
tutti i passi devono essere corretti,
la logica matematica e' precisa e espressiva,
esistono diverse logiche matematiche, ciascuna
con una diversa proof theory,

** Modus ponens

a and b -> a (se nel mondo e' vero a and b allora
sono veri anche a e b),

supponiamo di avere a e b nella base di conoscenza,
l'algoritmo dice che sono veri a e b,
allora si puo' derivare anche a and b,

- and elimination a & b -> a,b
- and introduction
- modus ponens (a, a=>b -> b)
- or introduction (a -> a or b, a or *),
  introduce ridondanza,
- doppia negazione: !!a -> a,
- resolution:
  a or !b, c or b or !d (sono le due formule date),
  la risoluzione vuole due formule tali per cui c'e'
  un simbolo o variabile proposizionale che compare
  in tutte le due formule ma con segno diverso,
  (!),
  qui e' vero perche' b compare con entrambi
  i segni,
  a questo punto le due formule vengono messe insieme
  senza i due elementi negati che si cancellano,
  si mette insieme con l'or,
  a or c or !d,
  la risoluzione vuole due formule (disgiunzioni
  di formule atomiche),
  o negazioni di formule atomiche,
  genero una nuova disgiunzione
  ottenuta mettendo insieme le prime
  due senza gli elmeneti che si risolvono.

 - risoluzione unitaria, almeno una delle due
   formule e' unitaria (formula atomica o negazione
   di formula atomica),
   es !b, b or c,
   da cui si deriva c perche' !b e b si cancellano,

Le regole di inferenza si applicano a formule con
un determinato formato, es la risoluzione generale
vuole due disgiunzioni, non gli and ma gli or,
l'altra cosa fondamentale e' che la procedura di inferenza
applica le regole di inferenza e ninet'altro,
la base di conoscenza e' lo stato a cui si applicano
gli operatori per generare gli stati successori.
Se applico il modus ponens prendo
dalla base di conoscenza due formule e ne aggiungo
una nuova.

** Metodi semantici

Posso usare il metodo inferenziale o
quello semantico,
ma gli assegnamenti diventano un numero
infinito nella logica del primo ordine,
la logica proposizionale e' molto potente
perche' molte altre logiche si possono
compilare in logica proposizionale.
