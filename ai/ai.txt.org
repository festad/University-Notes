
#+title: Intelligenza Artificiale

2022-09-26

Problema a stati multipli

Nulla osservabilita'
osservabilita' parziale (robot aspirapolvere), 8
possibili stati.

Un problema di ricerca a stati multipli ha un numero di belief
esponenzialmente piu' grande del numero degli stati, e'
l'insieme delle parti, 2^(8) -1 possibili stati.

Dato un diagramma degli stati, questi stati sono raggiungibili? (e'
una possibile domanda da esame).

Formalizzare un problema:
bisogna scegliere gli stati, formalizzare le azioni.
Esempio:
Problema dei missionari e cannibali:
- stati,
- azioni:
  - precondizioni se ci sono,
  - effetti,
- stato iniziale del problema,
- stato goal (insieme di stati goal,
  in questo caso lo stato goal e' che i
  missionari e cannibali sono tutti dall'altra
  parte del fiume).
- costo della soluzione trovata.


* Algoritmo generico di ricerca

Tutti gli esempi li vedremo con uno stato
iniziale,
L e' la lista iniziale degli stati,
se L e' la foglia diremo che non
esiste soluzione al problema.
Se L non e' vuota c'e' almeno
un nodo sulla frontiera, si sceglie
un nodo foglia (potrebbe anche essere random,
lo scegliamo dopo), dopodiche' controlliamo
se e' foglia e soddisfa il gol test,
se lo soddisfa allora riscriviamo n e
il cammino da nodo ad n,
perche' restituiamo n? perche' a volte
lo stato gol non e' noto (es provlema
delle n regine),
se il gol test non si applica viene eseguita
l'istruzione successiva (che non viene eseguita
se il gol test non ha successo),
tiriamo via n da L (lo abbiamo appena visitato)
e gli aggiungiamo i figli di n, n non e'
piu' una frontiera ma ci aggiungiamo i suoi figli,
come? quali? per il momento tutti, poi vediamo.
Ls strategia di ricerca determina come si costruisce
l'albero di ricerca, ci sono quelle
cieche o non informate che scelgono il nodo
dalla frontiera solo in base alla posizione nell'albero,
quelle euristiche o informate scelgono il nodo promettente
dalla frontiera usando informazioni esterne che c'entrano
parzialmente con la posizione nell'albero.
Un esempio di euristica e' il numero
di caselle fuori posto nel problema del piazzamento
dei numeri nel sudoku.

* Tecniche euristiche

2022-10-04
Best-first search

h*(n) = reale distanza di n dal gol piu' vicino (ci potrebbero
essere piu' stati che garantiscono il gol),
quando h(n) e' ammissibile l'algoritmo si chiama A*,
A per ammissibile, * indica che trova sempre la soluzione ottima.


Confronto tra euristiche:
ci sono due metodi per confrontare le euristiche a coppie:
il confronto teorico e il confronto sperimentale o empirico.

Confronto teorico: e' piu' difficile, richiede matematica pesante,
si deve dimostrare che per ogni stato l'euristica di un nodo
e' minore o uguale dell'euristica dell'altro, a patto
che entrambe le euristiche siano ammissibili.
Se h1(n)<=h2(n) per ogni n allora h2 e' migliore,
ma dipende dal problema e dalle euristiche.

Metodo sperimentale: molto utilizzato.
Bisogna scrivere un'equazione,
prendiamo tanti problemi (configurazione
iniziale random e finale fissa), risolvo tanti problemi
usando un'euristica e tanti usando un'altra,
quando risolvo un problema posso o considerare il cpu time
(ma non e' furbo) oppure posso contare il numero di nodi visitati,
chiamiamo N il numero di nodi generati da A* in un run (anche nodi
generati si puo' dire invece che visitati), poi si tiene traccia
durante la soluzione della profondita' dove si trova il nodo gol,
equazione: ...

Confronto tra l'euristica di manhattan,
confronto delle euristiche con il metodo sperimentale con la
costruzione dell'albero fittizio per vedere b*.

Nuovo algoritmo:

Iterative deepening

Una possibilita', simile a quella della ricerca cieca non informata
in profondita, ripetiamo una ricerca in A* dando un bound sulla
lunghezza della soluzione che stiamo cercando,
iterative deepening A*,
diamo un limite alla lunghezza del cammino che viene
incrementato iterativamente.
Dobbiamo capire il taglio,
potrei pero' ripetere piu' volte la stessa cosa,
scegliamo come cut g(n), perche' gli archi
non hanno costo unitario ma costo definito da g,

Con l'incremento di uno, se ripeto la ricerca e' garantito
che visito almeno un nodo in piu'.

Seminario: A* con tecniche ulteriori.
come lavorare sulla lista L, usando qualcosa in piu' della f
allo scopo di risparmiare memoria.

Parliamo di un'altra classe di tecniche.

** Tecniche di ricerca locale

hill climbing, funzione da massimizzare,
anche se noi h la minimizzavamo prima,
no problem, mettiamo il meno davanti e manteniamo
la regola di massimizzare invece che minimizzare,
l'algoritmo si chiama discesa del gradiente.

Non costruiamo piu' l'albero di ricerca,
invece di inserire i figli nella lista L si
sceglie un figlio (se l'euristica e' furba
sceglie la mossa giusta da fare, senno' sceglie
quello sbagliato),
scegliamo il migliore,
ovvero quello con h piu' basso (ho meno
lavoro da fare),
l'hill climbing pero' era stato formulato
come problema di massimizzazione,
sceglieva h maggiore,
si puo' pero' riformulare in maniera
duale l'euristica,
in genere si usa h da minimizzare in AI,
la distanza di Manhattan e' difficile da riformulare
una volta scelto il figlio si cancella il padre e tutti gli altri figli.
si fa una scelta vincolante che non permette di tornare indietro,

Tecniche dell'hill climbing + euristiche

*** Mosse laterali
Se non riesci a uscire dalla pianura migliorando ricmoincia da capo.

*** Stocastico a: con probabilita' per stati successori
Il prossimo passo non e' deterministico e univoco
ma e' un range di possibili operazioni
scelte con una probabilita',
quando si arriva al momento non deterministico si tira
una moneta sbilanciata, piu' esecuzioni possono essere
diverse a parita' di input.
Lo faccio perche' l'euristica ogni tanto sbaglia,
per compensare non la seguo sempre ma ogni tanto
faccio qualcosa di diverso da quello che mi dice.
 
*** Stocastico b con prima scelta migliorativa random


*** stocastico c con riavvii casuali _ mosse laterali


*** Simulated annealing


*** Ricerca locale Local Beam

Si puo' inserire la randomizzazione anche qui,
si scelgono anche
dei K che peggiorino

*** Tabu Search

Senza run paralleli, si introduce un po' di memoria
a Climb Hill, si memorizzano gli ultimi K stati
visitati o le ultime K azioni,
puo' evitarci dei loop,
sono tecniche che si prestano a spazi
di ricerca molto grandi, non voglio
avere un algoritmo che visita pochi stati,
devo avere un algoritmo che visita tanto
perche' lo spazio e' immenso e allo
stesso tempo abbia memoria sufficiente a
evitare dei loop, es K 10, 20, 100..
dipende dal problema specifico.
Se k passi sono sufficienti a uscire
dal minimo locale allora si puo' raggiungere il
minimo assoluto, senno' si rimane ancora
intrappolati nel minimo locale.

*** Enforced Hill-Climbing
Per ogni stato visitato usa una ricerca
in ampiezza per trovare un discendente
di S che abbia valore euristico
migliore di S.
Si ferma sul primo che trova migliorativo.

Trovato il nodo che migliora si butta via il resto,
si riparte dallo stato corrente, si controllano i successori.
Queste tecnica la ritroveremo perche' e' stata usata in un
sistema di pianificazione automatico con un'euristica macchina,
H si puo' calcolare automaticamente senza conoscere
il dominio del problema.

Se S e' un minimo locale molto profondo
serve una ricerca in ampiezza molto profonda,
il problema della ricerca locale e' legato
a come e' fatta la funzione euristica rispetto
agli stati del problema.

Se volessimo minimizzare la funzione
e mi trovassi in un minimo locale
i successori sarebbero peggiorativi,
se voglio uscire dal minimo locale
pero' devo scrivere un albero abbastanza
profondo, tanto quanto sono le azioni
necessarie a raggiungere un successore
migliorativo,
servira' una profondita' dell'albero elevata,
questa tecnica puo' non funzionare quando h
ha minimi locali profondi, e la memoria
si esaurirebbe nel migliore dei casi.

*** Algoritmi genetici
Con risultati misti, a volte funziona
e a volte e' disastrosa, richiama l'evoluzione
della popolazione di generazione in generazione,
nel processo evolutivo c'e' un miglioramento della specie.

Gli algoritmi genetici richiedono che uno stato
sia rappresentato con una stringa di numeri (elementi,
vettore),
nel problema delle 8 regine potrebbe essere
[riga della regina in colonna 1, riga della regina in colonna 2, ...].
Devo partire da un insieme di stati che rappresentano la popolazione,
faccio un processo evolutivo nel tentativo di trovare
un individuo che soddisfa il problema,
es l'assenza di attacchi tra regine.

Posso disporre le regine casualmente,
il problema del rompicapo dell-8 uguale, potrei iniziare con
posizioni casuali.

Determinata la posizione iniziale si fa una valutazione
euristica degli individui della popolazione,
negli algoritmi genetici l'euristica si chiama
funzione di fitness,
a questo punto selezioniamo dalla popolazione individui da accoppiare,
si scelgono sulla base della funzione euristica e in maniera stocastica,
chi ha una funzione euristica migliore deve avere piu' probabilita' di
essere scelto,
come si genera lo stato successore a partire da due stati?
Si mescolano le caratteristiche,
ci possono essere varie strategie, per es prendere un po' di piu' da chi
ha la funzione euristica piu' alta.

*** Algoritmo con ricerca online

Non ha senso pensare a tutta la soluzione,
potrebbe succedere che non ho tempo per pensare alla soluzione,
devo fare qualcosa in un secondo,
puo' essere necessaria la ricerca online
perche' il mondo non e' statico,
ho conoscenza parziale dell'ambiente e anche
delle mie azioni,
non posso costruire una soluzione che funzioni
sempre allo stesso modo,
la prossima azione da fare viene prima
calcolata e poi eseguita,
dopodiche' la gente deve osservare lo stato:
ci sono due casi:
- il mondo e' totalmente accessibile,
  l'agente sa com'e' l'ambiente dopo che
  ha effettuato l'azione,
- il mondo e' parzialmente accessibile

L'azione puo' avere costi diversi a seconda
dello stato che ha generato,
ma non sappiamo all'inizio quali sono gli effetti,
delle azioni,
le precondizioni delle azioni le conosciamo
ma scopriremo gli effetti delle azioni solo
dopo averle eseguite,
inoltre la funzione gol test decide se uno stato
e' gol o no.

Anche gli stati successori si conoscono solo
dopo aver eseguito tutte le azioni applicabili
nello stato, c'e' dell'apprendimento,
scopriro' come e' fatto il diagramma degli stati,
non lo so a priori.
Pero' ho la totale osservabilita', imparero' gli
effetti dell'azione, so sempre dove sono andato
a finire dopo aver compiuto l'azione.
Dopo aver eseguito l'azione imparo il suo costo e
il suo effetto.

La ricerca in ampiezza non puo' essere resa online
La ricerca in profondita' puo' essere
resa online perche' la ricerca avviene di pari
passo con la valutazione,
posso spostarmi in uno stato e man mano che
scendo eseguo anche l'azione che mi fa scendere,
l'unico problema e' quando
arrivo in fondo, ovvero trovo un vicolo cieco,
quindi quando arrivo in fondo?
Devo aver inserito una regola, l'azione
che fa tornare indietro,
l'azione di reverse che riporta al padre,
una volta tornato al padre posso chiedermi
se ha altri figli,

2022-10-11

Algoritmi di ricerca online,
concetto di backtracking,
vuol dire tornare indietro in un punto della ricerca,
quando siamo arrivati a un nodo senza successori si fa
backtracking,
oppure quando uno stato e' nella closed list
e si evita di rivisitarlo,

** Ricerca in profondita' online

result e' inizialmente vuoto e rappresenta
gli effetti delle azioni,
inizialmente l'algoritmo non sa nulla,

unexplored e' una tabella
che lista per ogni stato quali sono le
azioni che non si sono ancora provate
ad applicare,
unbacktracked: tiene traccia di tutti
i possibili punti di ritorno della ricerca,

ad ogni run abbiamo mmeoria dell'ultimo stato (precedente),
l'ultima azione eseguita (+ le tre variabili globali,
result, unexplored e unbacktracked).

Pseudocodice:
le azioni disponibili in uno stato sono statiche,
si sanno sin dall'inizio e non cambiano,
se s=0 allora s==s',
aggiungo s alla lista degli unbacktracked quando
da s mi sposto a s',
se e' la prima volta che entro in s' ho la lista
di tutte le azioni da eseugire,
se invece ci ero gia' passato
la lista unexplored[] potrebbe non essere
vuota perche' ho gia' provato qualcosa,
quindi prendo un'azione (la prima) disponibile
in unbacktracked (la prima perche' facciamo ricerca in
profondita') e aggiorno lo stato vecchio che non sara'
piu' s ma s', lo stato corrente in cui sono,
return a fa eseguire a,
nel caso in cui non abbiamo piu' azioni da esplorare
vediamo se c'e' un punto indietro che abbia una strada
aperta (potrebbe anche non esserci, per es. se il problema non
ha soluzione), se non c'e' ritorno fallimento,

es pg 69
terza iterazione
S = B
S; = C
unexp[C] = (03)
unback[C] = (B)
Q = 03
unexp[C] = ()

S' NON e' un nuovo stato

S = C
S'= A
non tocco unexplored
unexplored[A] e' vuoto
unback[A] e' vuoto?
unbac[A] = C

e' un algoritmo corretto e completo,
e' un algoritmo che sa fermarsi e riconoscere
che non c'e' soluzione pur essendo
a parziale conoscenza,
ma con l'assunzione che abbia totale osservabilita',
inoltre ha una complessita' limitata, infatti
ogni arco viene visitato al piu' due volte,
il numero di chiamate resta polinomiale,
le azioni di reverse sono necessarie,
quindi gli archi devono essere bidirezinoali,
ci sono anche altri algoritmi online senza
questa assunziuone ma potrebbero non trovare la soluzione.

actions[] contiene solo le azioni normali,
non quelle di reverse o backtracking


** Random walk

ricerca locale online,

in ciascun nodo ho una possibilita' per progredire
e due per regredire,
da questo diagramma si evince che se mi muovo
in modo casuale ho una doppia probabilita'
di peggiorare rispetto a quella di migliorare,


pg. 73,
Conosciamo h(s) della funzione euristica,
conosciamo i valori euristici per ogni stato,
inizialmente siamo a meta' della catena bidirezionale,

** LRTA*-Agent

Ripetendo l'algoritmo tante volte si riesce
a trovare la soluzione ottima ma non la prima
volta, la funzione euristica h viene
aggiornata ogni volta,


* Constraint Satisfaction Problems

** Map-coloring

Gli stati che soddisfano il gol test si chiamano soluzioni,
non siamo interessati ai passi per raggiungere la
soluzione ma a trovare una soluzione,
vogliamo trovare uno stato che soddisfi il gol test.

Il csp, nel caso di vincoli binari, puo' essere
modellizzato con un grafo.
La Tazmania non ha vincoli, non e' collegata a niente,
la semantica degli archi puo' significare diverse
cose a seconda del problema,
qui significano un vincolo della diversita' dei colori,

ad occhio si vede (slide 6) che il grafo
non e' connesso, posso decomporre il problema
in sottoproblemi uno diverso dall'altro,
riducendo la complessita' del problema originale.

Nel sudoku ci sono 9^{81} stati possibili,
i vincoli sono quelli del problema:

i vincoli binari sono preferiti.
Per ogni riga: $\frac{9^2-9}{2}=36$ vincoli,
il numero totale di vincoli e' (36*9*3),
il grafo e' sparso perche' il numero degli archi sarebbe
$\frac{81^{2}-81}{2}=3240$, molti di piu'.

Nel problema delle 8 regine
ci sono 8^8 possibili configurazioni,
i vincoli sono $\frac{8^2-8}{2}=28$ e tutti uguali,
anche il problema delle regine e' formalizzato come
un CSP.

** Backtracking search

Un valore viene assegnato solo se non e' in conflitto
con gli altri a differenza di prima,
il gol test si applica in modo incrementale.

Per ogni valore x in X deve esistere un valore y nel
dominio della variabile y,
se non e' vero x viene tolto dal dominio di X.


** Arc consistency

20221018


n -> numero di variabili
d -> cardinalita' del numero delle variabili

In input c'e' il csp, ogni variabile ha il suo dominio,
inizialmente mettiamo tutti gli archi del csp,
nel grafo c'e' un arco per ogni coppia di variabili,
gli archi sono bidirezionali,
se c'e' un vincolo di diversita' tra x e y
dovremo mettere (x,y) e (y,x) nella coda,
la coda viene processata finche' diventa vuota,
poi prendo il primo elemento e forzo la consistenza
tra le due variabili selezionate,
forzare la consistenza si fa con la funzione RM-INCONSISTENT-VALUES(X_i, X_j),
poi faccio il controllo della proprieta' di consistenza,
se non c'e' vincolo tra la coppia allora il check e'
automaticamente soddisfatto,
se ho modificato il dominio di x_i potrebbe esserci
un'altra variabile x_j per cui non vale il vincolo
di consistenza,
devo inserire tutte le coppie per fare nuovamente il check.

Esempio:
x_i -> x_j

nel fare il controllo modifico il dominio di x_i,
quindi prendo tutte le x_k nel vicinato di x_i,
[x_k1, x_k2, x_k3..] che hanno un vincolo con x_i,
potrei anche metterle tutte ma sprecherei risorse,
metto solo quelle nel neighborood,
Neighbor[x_i],
si inseriscono tutte nella coda perche'
ora che x_i e' cambiato il controllo fatto
prima potrebbe non essere piu' valido,
prima dicevamo che in x_i c'era almeno un
valore nel dominio che era != da x_j,
es x_i = {3,9},
x_k1 = {3,7},
se tolgo il 9 x_k1 e x_i non soddisfano piu'
il vincolo di diversita'.

L'algoritmo termina?
Tolgo ma aggiungo anche elementi nella coda, magari
non si svuota mai...
in realta' si svuota perche' le coppie sono finite
e la stessa coppia puo' entrare nella coda un numero
finito di volte,
al massimo tante quante posso cambiare il dominio
della variabile (che ogni volta che cambia puo'
diventare piu' piccolo ma mai piu' grande),
le coppie del vicinato rientrano nella queue
un numero massimo pari alla cardinalita' dei domini.

L'algoritmo termina perche' una coppia entra in queue
al massimo d volte (d=max numero di elementi in una variabile),

Costo: O(n^2d^3),

all'interno del while eseguiamo un d^2,
dobbiamo contare le coppie dei nodi che entrano
nella queue nel caso peggiore,
inizialmente le coppie sono n^2-n, O(n^2),
per ogni ciclo devo eseguire un algoritmo che costa
d^2,
O(n^2)*O(d^2),
la stessa coppia puo' rientrare nella queue al massimo
d volte,
quindi n^2*d*d^2,

si pou' fare pruning dei valori,
e' una forma di inferenza potente nell'algoritmo di
backtracking.
Nel fare l'arc consistency i valori possono essere
eliminati.

** Backtracking with inference

Viene chiamato il backtrack (ricorsivo) e controlliamo
alla fine della ricorsione se l'assegnamento e' completo,
il check di consistenza dei vincoli e' fatto man mano
che assegno valori alle variabili,
prendo una variabile (the most constraining variable)
e provo tutti i possibili valori, correntemente nel dominio,
se il valore e' consistente con l'assegnamneto allora
incremento l'assegnamento col nuovo assegnamento a var,
dopodiche' applico l'arc consistency,
la applico al csp modificato,
alcune variabili hanno valore fisso,
il csp e' dinamico,
altre variabili potrebbero avere
un dominio ristretto,
se non c'e' fallimento aggiungo alle inferenze
che ho fatto faccio un assegnamento nullo,
dopodiche' faccio backtracking sulle variabili
che rimangono da assegnare,
es. esercizio dei sudoku,
abbiamo valori settati inizialmente,

3-consistenza = path-consistenza,
eliminare le coppie che non soddisfano la
proprieta', per rendere il vincolo piu'
restrittivo,

il problema alla lavagna e' arc consistente
ma non path consistente (no alla coppia 2,2, perche'
2<=2<2 non e' vero.

La ricerca locale per i CSP
non e' completa, non puo' accorgersi
di aver considerato tutto e di poter
terminare la ricerca,
non si ha la garanzia di aver
visitato tutto,
si parte invece che da un assegnamento
vuoto come nel backtracking, da un assegnamento
aleatorio e si controlla se e' una soluzione,
se non lo e' si inserisce una perturbazione
con un numero limitato di possibilita',
si prende una variabile scelta in modo casuale
ma tra quelle che hanno valore corrente in conflitto
con quello di qualche altra variabile,
se il csp non e' una soluzione c'e' almeno un conflitto,
dopodiche' si vede come cambiare valore,
es euristica del min conflict,
si sceglie un valore che porta a ridurre il numero
di constraints violati,
oppure invece che minimizzare i conflitti si
massimizzano gli assegnamenti leciti.
Se stiamo massimizzando la nostra euristica: hill climbing,
altrimenti gradient descent.

* Seminario su $A^{\star}$

Se h e' ammissibile allora troviamo l'ottima,
ma potrebbe anche essere troppo costoso trovare l'ottimo,
allora puo' essere tollerabile trovare sol subottime, implementiamo
quindi h non ammissibile.
Ci sono soluzioni subottime con limiti, non troppo distanti
dall'ottimo, con un bound (es al massimo 3 volte peggio
dell'ottimo),
Vediamo tecniche che vanno in contro a questa esigenza.

- any solution: una sol qualsiasi
  senza garanzia sulla qualita;,
  greedy best first search (guardano solo
  h),

- bounded subottimal search: voglio
  trovare una sol : il costo e' minore di b*sol_ottima,
  se b=1 cerco l'ottimo,
  una sol e' b-ammissibile se soddisfa
  tale ugualianza,

- bounded cost search, trovare
  una sol tale che cost<=C,


** BSS - FOCAL Search

Ci si focalizza su certi elementi della open list (frontiera),
la focal list e' fatta da un sottoinsieme della open list,
devo avere una euristica h ammissibile,
(es. numero di caselle malposte, manhattan),
viene mantenuta la lista di sottoinsiemi (focal),
in cui metto gli elementi tali che $f(n) (=g(n)(=h(n)) <= \mbox{ il miglior nodo}$,
quando prendo un nodo dalla lista L non prendo piu' il nodo migliore in base
a L ma mi concentro solo sugli elementi in FOCAL, perche' contiene gli elementi
che soddisfano il requisito che voglio (quello di <=).

(Pearl - Heuristic search),
si sceglie il nodo, lo si toglie sia dalla focal sia dalla L,
se best soddisfa il gol test lo ritorno,
se f_min e' cresciuto allora fix_local,
siccome la open cambia la L, puo' anche cambiare il valore
minimo di f dei nodi nella open list,
se ho 10 nodi puo' essere che il nodo minore sia 5,
dopodiche' potrebbe diventare 4,
se cambia il valore di f_min, se e' cresciuto, allora
aggiorna il contenuto della focal list,
perche' tiene tutti i nodi che hanno f <= b*f_min,
$f(n) \leq Bf_{{min}$,
se decresce non modifico perche' non devo aggiungere
niente,
i neighbors sono i successori di best,
li aggiungo alla open list, se soddisfano
il requisito <= li aggiorno anche alla focal,
quando prelevo un nodo da espandere
lo prendo da focal e non da open,
in questo modo riesco a dimostrare che
trovo una soluzione subottima ma bounded con
il vincolo di B desiderato,

** BSS Weighted A^\star
Se w = 1 e h ammissibile troveremo la sol ottima,
g_n e' il miglior cammino conosciuto per raggiungere
n,
w tipicamente non e' < 0 ma e' >=1,
se w=1 siamo in a*,
se w > 1 abbiamo un regime diverso,
diventa stra dominante il secondo termine,
greedy best first search,
per i w non troppo grandi non trovo
la soluzione ottima perche'
se w e' 1.2 potrebbe essere che 1.2 * h non sia
piu' ammissibile,
potrei raggiungere un gol non ottimo,
pero' sto dando piu' peso all'h,
e se e' progettata bene mi aiuta a trovare
un nodo gol,
mi sto dimenticando di g (quanto mi occorre
per arrivare a quel nodo li'),
si puo' dimostrare che c'e' corrispondenza
tra weighted e focal, perche' w a* e' un
caso speciale della focal, permette di trovare
soluzioni w-ammissibili (B=w),
sono di costo peggiorativo non piu' di w le soluzioni trovate.

(Vediamo anche metodi per combinare piu' euristiche)

BSS e' una best first search con
f(n) = g(n)+W*h(n),
costo per arrivare dalla radice a n + euristica (ammissibile
o non) pesata (W),
se h e' ammissibile con W=1 abbiamo A*,
se e' > 1 l'euristica complessibile
potrebbe non essere ammissibile,
se W e' molto grande la componente g non ha
piu' nessun ruolo (viene mangiata),
quindi con W grande e' la greedy best first search,
guarda in avanti senza ricordarsi del costo gia' speso.

FOCAL: soluzioni b ammissibili,
si possono trovare soluzioni W ammissibili con BSS,
W -> costo della soluzione ottima.

** BSS Explicit estimation search (ESS),
bounded subottimal search,
trova soluzioni che hanno la garanzia di un bound
peggiorativo rispetto all'ottimo, ma non la soluzione ottima,
in questo framework c'e' l'ESS, un'altra tecnica (come FOCAL e l'altra),
abbiamo 3 euristiche da specificare:
- euristica ammissibile h, vogliamo sia ammissibile,
  chiamata cost-to-go, 
- $\hat{A}$, cost-to-go NON ammissibile, piu' aggressiva, meno
  cautelativa, osa di piu', cerca di avvicinarsi di piu'
  e potrebbe anche sbagliare,
  potrebbe essere non il numero delle azioni (azioni non unitarie),
  
- distance-to-go, anche questa non ammissibile,
  conta quante azioni servono per arrivare al gol,
  a differenza del precedente, (es. costo delle azioni
  per arrivare al gol, 5+7+9, sono 3 azioni,
  la dtg conta il 3, la ctg conta 5+7+9).

h(n) e' l'unica ammissibile per forza.

Scegliamo con una combinazione di possibilita' come
combinarle nell'algoritmo,
f, \hat{f}, d (elemento greedy, guarda in avanti, conta le azioni
per arrivare al nodo gol piu' vicino),
durante la ricerca si tiene traccia dei nodi importanti:
nella lista L valutiamo i nodi in base \hat{f} e \hat{d},
la seconda non la fa A*, la terza dice "considera tutti
i nodi nella lista open tali per cui \hat{f}(n) deve essere
<= b*\hat{f}(best_f)",
per tutti i peggiorativi al massimo b rispetto a fhat considera
quello piu' vicino al gol,
ad ogni espansione di nodo viene scelto dalla lista open
il nodo migliore secondo questo criterio:
se il meglio rispetto a fhat (non ammissibile) e' <= b*f(best)
allora scegli questo,
considero il miglior nodo che verrebbe preso da A* (prima euristica),
moltiplico il valore scelto da A* per b, se il miglior
nodo seguendo l'euristica non amm e' <= b*valore scelto da A*
allora scelgo quello con l'euristica cattiva (fhat), altrimenti
scelgo quello che avrebbe scelto A* (prima euristica, f),
prima si considera la terza euristica e se non va
scelgo il secondo criterio e lo confronto con quello che farebbe
A*,
in ultima istanza fai quello che farebbe A*,
A* garantisce l'ottimo ma ci mette tanto tempo,
le altre euristiche ci portano a un gol piu' velocemente
perche' usano euristiche piu' cattive,
con la disuguaglianza rimaniamo dentro al bound,

**BCS - Potential search,
abbiamo in input un costo C, espande i nodi
secondo la probabilita' che questi siano parte
di un piano avente costo <= C,
mi confronto con C quando sono nel nodo n,
uso la formula $u(n)=\frac{C-g(n)}{h(n)}$,
a parita' di eutistica (g<=c, tutti nodi
con costo inferiore a c),
(sin dall'inizio diciamo che c'e' una soluzione con costo C,
adesso pero' la devi trovare),
h(n) e' un'euristica,
a parita' di euristica scegliamo il nodo con g(n) piu'
piccolo e a parita di g(n) scegliamo quello con euristica
minima,
guidiamo la ricerca tenendo conto di C e privilegiando
i nodi rispetto alla funzione potenziale.
C e' dato in input ma puo' anche essere calcolato
dinamicamente considerando il nodo con l'f piu'
basso in quel momento, al posto di C che e' il nodo
della soluzione mettiamo b*f_min,
in questo modo usiamo una dynamic potential search,
quale sia meglio dipende dal problema.

L'anytime search la saltiamo, facciamo solo la definizione.
Gli algoritmi anytime producono iterativamente
soluzioni una dopo l'altra, una prodotta e'
in genere meglio delle precedenti,
sono soluzioni diverse,
si guarda non tanto la qualita' ma la diversita',
come si fa?
Versione ovvia: continuare la ricerca,
quando trovo una sol con un' h non ammissibile
allora (sol non ottima) aspetto che arrivi un'altra
soluzione, la lista L conterra' altri nodi
e vado avanti con la ricerca,
termino quando L e' vuota,
quando trovo la prima sol quella mi da'
un bound sulla qualita' della soluzione,
vado avanti e se trovo una sol con costo migliore
la fornisco in output altrimenti se ne trovo
una a costo 99 la do',
non so mai se la sol che do e' ottima ma
l'ultima che do' in output (non l'ultima trovata)
sara' migliore della precedente,
garantisce l'ottimo anche se h e' inammissibile
ma devo esplorare tutto l'albero di ricerca.
Ci sono tecniche di search che man mano trovano
una sol modificano l'euristica (non proseguono
come prima) ma cambiano l'euristica affinche'
la ricerca non porti a sol di cattiva qualita',
repairing search,
poi c'e' la restarting search,
ogni volta riparto da capo modificando il problema
per assicurarmi di non trovare soluzioni
di qualita' peggiore.

Facciamo la tecnica per la gestione delle stime (soft-bound),
l'ultima,
supponiamo di avere una stima di quanto costa
la sol, intuitivamente e ' ragionevole perche'
anche nei preventivi per organizzare un viaggio
uno si fa' un'idea di quanto spendera',
ma e' solo una stima,
supponiamo di avere un bound soft,
si possono prendere problemi
come il rompicapo dell'8 risolti,
un algoritmo di machine learning
puo' imparare a stimare i costi,
i passi per risolvere un problema di ricerca,
supponiamo di avere il bound,
possiamo usarlo per aiutare la ricerca?
iniziamo con bfs, una ricerca chiamata
hsearch non ammissibile, una h ammissibile e C,
usiamo la versione di algoritmo del W A*,
la funzione euristica di WA* tiene conto sia
di g che ti C e h_search..
questo h_bound (l'euristica che inventiamo),
e' definita prendendo l'euristica non ammissibile
e la moltiplichiamo per un fattore moltiplicativo
formato da c diviso (il conto che farebbe A*, h_delta(n)),
h_search non e' ammissibile,
viene modificata aumentandola o decrementandola in base al fattore,
se siamo molto sotto C la frazione diventa piu' grande,
se siamo sopra C stiamo andando oltre e h_search viene
penalizzata dalla frazione che diventa piu' piccola,
se i nodi hanno la componente molto minore
di c sono penalizzati,
voglio trovare la sol che costa C,
non perderti sui nodi che hanno la f troppo bassa,
perche' li sotto non c'e' la soluzione, i nodi >= C
sono piu' probabili da trovarci la soluzione se si parte
da li',
succede che se C che adotto come stima,
se il budget e' alto e posso usare tanti soldi e' piu' facile
trovare la soluzione,
se C e' vicino a quello ottimo rischiamo
di seguire troppo A* e fare troppa fatica,
se invece C non e' vicino all'ottimo
sara' piu' facile da trovare,
andrebbe un po' esagerato il costo C
se il nostro obiettivo e' trovare una sol (non
per forza la migliore),
cosi' la scelta viene nuovamente modulata
cercando di spegnere gradualmente il fattore
che moltiplica h_search,
lo facciamo con un esponente (1-p_rate)
che diventera' 1 quando il p_rate diventera' 1,
confrontiamo il n di nodi espandi dalla ricerca
con il numero di nodi espansi tali che g(n)+h(n) e' superiore
a c,
quando questo numero tende a 1 stiamo facendo troppa ricerca visitando nodi
che sono soluzioni piu' costose di c,
se g(n)+h_delta>c vuol dire che attraverso n
trovero' una sol piu' grande di c (perche' h_delta e' ammissibile),
se sono gia' molto avanti con la ricerca
e ho esplorato molti nodi oltre a c allora i due numeri
tendono a essere uguali (rapporto -> 1),
l'obiettivo e' velocizzare la ricerca,
voglio arrivare il prima possibile a una soluzione,
concentrandomi su nodi vicini a c (inutile
spendere tempo su percorsi piu' brevi, voglio
andare dove c'e' la sol a costo c, senza tentare
di risparmiare perdendo tempo).


* Test intermedio

Rimane tutto uguale a parte il seminario.
Potrebbero esserci domande sulla definizione
dei vari agenti,
semplici, stato e mondo, con gol e utilita',
gli ambienti in cui opera, deterministici,
con osservabilita' parziale.. diagramma degli
stati che diventa diagramma dei belief.

1 Es del robot aspirapolvere,
problemi con contingenze,
effetti non deterministici,
es che quando aspiro in una locazione
pulita potrebbe far cadere dello sporco,
se sono in uno stato che non ha sporco
non devo aspirare o potrei sporcare,

2 descrivere la complessita' computazionale
dell'algoritmo a approfondimento iterativo,
complessita' temporale,

Evitare cicli:
nella lista open n1 e n2 sono lo stato,
dentro ci deve essere il percorso dalla radice a n1,
ci deve essere un percorso alla radice,
se prendo n1 e non soddisfa il gol test, genero
il figlio e controllo che il figlio
non sia sul cammino che dalla radice
conduce al padre altrimenti sarebbe un ciclo:
[radice] --> ((figlio)) -->  [padre] ---> [figlio]
                 ^                            |
                 |                            |
                  ----------------------------

Formula del simulated annealing,

la funzione consistente garantisce di trovare una sol ottima
e c'e' la proprieta' di monotonicita' per cui se
incontro un nodo che ho gia' incontrato
sono sicuro che lo sto incontrando attraverso
un percorso che non e' migliore del precedente,
quindi non procedo piu' perche' quello nuovo
e' peggiorativo,
se A* e' equipaggiato da una lista di nodi chiusa
e l'euristica e' consistente se incontro
un nodo nella closed list so che il percorso
nuovo non e' migliore del precedente, faccio
pruning e non aggiungo il nodo alla open list,
se l'euristica e' solo ammissibile dovrei,
se non voglio aggiungere nuovamente il nodo,
fare il controllo che il percorso sia effettivamente
peggiore di quello trovato prima, il che non e' detto,
quindi nella open list devo scrivere anche i costi
del percorso migliore trovato per raggiungere lo
stato dalla radice.

7 descrivere almeno una delle seguenti
tecniche in hill climbing (mosse laterali o prima scelta),

- prima scelta: il vicinato (stati successori) valutali,
  comincia dal primo, confrontalo col corrente, e' migliorativo?
  no, continua, il prossimo e' migliorativo? si, acecttalo,
  mentre hill climbing li valuta tutti,
  e' utile quando ci sono tanti figli, 
- mosse laterali: anche se nel vicinato
  non c'e' nulla di meglio e ti fermeresti, cerca
  comunque (sei in una pianura) vai avanti lo stesso
  e scegli elemento con la stessa qualita',
  e' utile perche' si spera che la pianura  non sia vasta
  e e' abbastanza piccola da migliorare con poche
  mosse laterali.

8 differenza in formulazione di problema offline e online,
perche' l'online funziona solo con azioni reversibili
(dfs), il problema offline consente
di trovare l'intera soluzione prima di effettuarne l'esecuzione,
in quella online devo trovare la prossima azione, eseguirla,
abbiamo molta meno conoscenza,
nel problema online non sappiamo gli effetti delle azioni,
gli effetti delle azioni si sanno solo dopo averli eseguiti,
il diagramma delle azioni non e' potenzialmente esplicitabile
come nel caso offline prima di eseguire le azioni,
le azioni devono essere reversibili altrimenti non posso
implementare la dfs con backtracking,

9 tecnica del forward checking (con esempio per illustrare),
ogni volta che associo a x un valore v  vado a vedere
per tutte le altre variabili y legate con un vincolo
ad x se nel dominio delle variabili y c'e' qualche
valore in conflitto con v dato a x,
se il vincolo e' != e instanzio x con 1 controllo le y,
il check e' sui domini delle variabili non istanziate,
si rimuovono dal dominio i valori che creerebbero
conflitti.

20221026

* Rappresentazione della conoscenza

I CSP sono un linguaggio che rappresenta una conoscenza,
sono dotati di un linguaggio sintattico,
rappresentiamo qualcosa di vero nel mondo,
la semantica sara' legata a qualcosa
di vero,
inizialmente abbiamo formule che corrispondono a qualcosa
nel mondo reale, poi voglio che le nuove
formule rappresentino qualcos'altro che sia una conseguenza
logica delle formule originarie,
entails = implica,
follows = conseguenza (logico, semantico) (entails, sintattico),
una procedura di inferenza e' un algoritmo
che deriva nuove frasi da frasi iniziali,
puo' essere corretto, completo, tutti e due,
corretto (sound) = per ogni formula derivata, l'insieme di formule iniziali
e' chiamato knowledge base,
per ogni formula phi derivata dall'algoritmo, phi deve
essere una conseguenza logica (liv semantico) della knowledge base,
e' completo se vale il viceversa,
proof theory: e' relativa a un particolare linguaggio,
(es logica proposizionale),
la teoria della dimostrazione specifica un insieme
di passaggi che sono corretti,
i passi di inferenza sono le operazioni dell'algoritmo
che fa inferenza,
tutti i passi devono essere corretti,
la logica matematica e' precisa e espressiva,
esistono diverse logiche matematiche, ciascuna
con una diversa proof theory,

** Modus ponens

a and b -> a (se nel mondo e' vero a and b allora
sono veri anche a e b),

supponiamo di avere a e b nella base di conoscenza,
l'algoritmo dice che sono veri a e b,
allora si puo' derivare anche a and b,

- and elimination a & b -> a,b
- and introduction
- modus ponens (a, a=>b -> b)
- or introduction (a -> a or b, a or *),
  introduce ridondanza,
- doppia negazione: !!a -> a,
- resolution:
  a or !b, c or b or !d (sono le due formule date),
  la risoluzione vuole due formule tali per cui c'e'
  un simbolo o variabile proposizionale che compare
  in tutte le due formule ma con segno diverso,
  (!),
  qui e' vero perche' b compare con entrambi
  i segni,
  a questo punto le due formule vengono messe insieme
  senza i due elementi negati che si cancellano,
  si mette insieme con l'or,
  a or c or !d,
  la risoluzione vuole due formule (disgiunzioni
  di formule atomiche),
  o negazioni di formule atomiche,
  genero una nuova disgiunzione
  ottenuta mettendo insieme le prime
  due senza gli elmeneti che si risolvono.

 - risoluzione unitaria, almeno una delle due
   formule e' unitaria (formula atomica o negazione
   di formula atomica),
   es !b, b or c,
   da cui si deriva c perche' !b e b si cancellano,

Le regole di inferenza si applicano a formule con
un determinato formato, es la risoluzione generale
vuole due disgiunzioni, non gli and ma gli or,
l'altra cosa fondamentale e' che la procedura di inferenza
applica le regole di inferenza e ninet'altro,
la base di conoscenza e' lo stato a cui si applicano
gli operatori per generare gli stati successori.
Se applico il modus ponens prendo
dalla base di conoscenza due formule e ne aggiungo
una nuova.

** Metodi semantici

Posso usare il metodo inferenziale o
quello semantico,
ma gli assegnamenti diventano un numero
infinito nella logica del primo ordine,
la logica proposizionale e' molto potente
perche' molte altre logiche si possono
compilare in logica proposizionale.

20221026

Regole di inferenza.
La base di conoscenza iniziale e' lo stato iniziale,
si modifica con le formule derivate dalle regole di inferenza.
Terminazione:
- chiusura deduttiva della base di conoscenza,
  abbiamo derivato tutto cio' che e' derivabile,
  non e' detto che sia la cosa migliore, potremmo
  derivare un numero esponenziale di implicazioni
- ...

Il ragionamento semantico lavora direttamente sulle interpretazioni e
sui modelli, Model checking, controllo se esiste
qualcosa che rende le formule vere,
sfruttando per lo piu' il teorema:
KB & !a,
con il model checking controllo se esiste un modello,
se esiste allora la formula e' valida e quindi
a non e' conseguenza logica perche' se assumo
il suo contrario e' ancora vera,
mentre se non esiste alcun modello allora
a e' conseguenza logica perche' se assumo
il suo contrario e' impossibile.

Un problema di CPS temporale puo' essere
trasformato in SAT, artificiale e con vincoli
particolari, se risolvo SAT risolvo anche
il problema principale,
si chiama "Riduzione di problemi in SAT".

Semantico -> regole di inferenza
Deduttivo -> model check

Conjunctive Normal Form (CNF),
si puo' dimostrare che la regola
di inferenza e' sound (corretta) con le tabelle
di verita'.

Formato CNF -> conjunctive normal form,
congiunzione di disgiunzioni.

a => b === !a || b

a <=> b === (a => b) & (b => a),
sat cerca un modello in conjunctive normal form,
ciascuna clausola e' un vincolo.

La clausola vuota e' la formula che non ha nessun letterale.

Una procedura di inferenza e' completa se
e' in grado di dare una risposta per qualsiasi
formula a, (ed e' corretta),
una procedura di inferenza che applica solo la regola
di inferenza prende tutte le coppie
possibili dalla KB, in teoria andrebbe bene
ma in pratica e' troppo, bisogna selezionare alcune
coppie e non farle tutte,
si chiama "strategia di risoluzione" il metodo con cui
si scelgono le coppie.

Perche' attraverso il metodo di rifiutazione
e non quello diretto?
Perche' quello diretto non e' completo, e' corretto
ma non completo.

La KB non deve essere in contraddizione da sola,
se dalla KB arrivo alla clausola vuota dopo qualche
passo di inferenza allora e' inconsistente.
se KB e' inconsistente il metodo non e' applicabile,
altrimenti direi "si" a tutto.

Nuova procedura di inferenza (che funziona
solo per un sottoinsieme della logica
proposizionale pero').
Se ci sono solo le clausole di Horn si possono
usare altre tecniche piu' veloci.
Le clausole di Horn sono il
fondamento della programmazione logica.

Le clausole di Horn sono:
...

** Forward chaining



** Backward chaining

Backword e' molto piu' efficiente di forward nonostante
la complessita' sia la stessa,
ogni iperarco e' attraversato una volta sola,
complessita' lineare nel numero delle formule,
anche se la base di conoscenza contiene
10000 formule non e' un problema
per l'algoritmo processarli.

La programmazione logica usa clausole
definite, + una serie di trucchi
per gestire la negazione per fallimento,
l'interprete non sta facendo una vera dimostrazione logica,
la prog logica e' nata ispirata dalle dimostrazioni di teoremi,
noi non facciamo programmazione logica pero'.
La programmazione logica ha anche variabili,
non solo proposizioni.
La forward chaining e' data driven,
dati dei fatti lui va in avanti,
la backword e' chiamata gol driven perche'
parte da un punto specifico del grafo e va indietro
in modo piu' focalizzato.

Facciamo una dimostrazione della completezza
del concatenamento in avanti.

Applicare modus ponens in avanti e' una
procedura completa,
una volta che ho il grafo posso
attraversare il grafo e arrivare al nodo,
come dimostriamo che l'algoritmo e' completo?

** Proof of completeness

L'algoritmo di forward checking
applica la regola di inferenza
(modus ponens),
si guardano le premesse,
se ci sono gia' nella KB allora aggiungo
alla base di conoscenza b,
ora che ho aggiunto b potrebbero
esserci nuove regole che ora posso applicare
e prima senza b non potevo,
continuo a vedere se le regole
sono applicabili finche' ho applicato
tutto quello che si poteva applicare.
Guardo dentro la base di conoscenza (base deduttiva)
se c'e' la formula atomica che dovevo dimostrare,
se c'e' allora era una conseguenza logica,
senno' no.

supponiamo
KB = {A,C,F,A => K...},
prendo tutte le formule atomiche (in questo caso 3),
avranno come valore true:
A = T,
C = T,
F = T,
le altre le metto false:
B = F,
D = F,
E = F,
se compare e' vero e se non compare e' falso.

Ogni clausola o formula implicativa e' vera in m;
la base di conoscemza avra' come modello m,
per quale motivo l'assegnamento e' un modello?
Perche' sicuramente le formule atomiche
sono soddisfatte da quel modello e le altre
sono implicazioni,
se non sono soddisfatte c'e' qualche implicazione falsa,

deve esserci una formula non vera,
quindi un'implicazione (sono tutte implicazioni
le formule),
un'implicazione e' falsa quando Q e' falsa e A,C,F veri:
A & C & F => Q,
ma se nella KB abbiamo A,C,F allora ci deve essere stato
dentro anche Q senno' non e' vero che avevamo derivato Q,
quindi Q e' T, ma allora A,B,C => e' vera,
CONTRADDIZIONE!

m era stata costruita col modus ponens,
guardando la base di conoscenza con tutte le formule
derivate,
e' impossibile che una delle formule costruite
sia falsa,

proof of completeness

m e' un modello della base di conoscenza.

dentro a m Q e' falso,

assunzioni:
1: kb != q
2: FC non deriva q

Lemma: m e' modello di KB

Per definizione di |=
m deve essere un modello di q,
tutti i modelli della base di conoscenza
sono anche modelli di q per definizione di
implicazione logica (|=),
MA m non puo' essere modello di
q perche' dentro m c'e' q falso (perche'
stiamo assumendo che m non derivi q),
se l'algoritmo non deriva q allora deve
essere false,
se q false allora il modello non puo' soddisfarlo
perche' vuole che q sia true,
dentro a m q e' false perche' fc non l'ha derivato,
allora per def di implicazione m dovrebbe essere
modello di q ma non puo' esserlo perche in m
la q e' false,
quindi almeno una delle nostre assunzioni e' falsa,
-o q non e' conseguenza logica di KB o FC deriva
q adl forw ch o tutte e due.

Esercizio

vogliamo fare model check delle clausole,
cerchiamo un modello che renda
le formule vere,
i simboli nell'algoritmo dpll sono
P,Q,L,D.. (lettere senza il not),
si guarda prima quali sono i simboli puri:
Q e' puro,
quindi gli assegnamo false perche'
compare solo con !Q,
possiamo ogni volta che cambiamo qualcosa
nell'assegnamento vedere le clausole che sono
vere,
se q e' false sappiamo che la prima e' vera
(!P or !Q),
se metto da parte la prima so che
P diventa puro perche' compare solo
un'altra volta (se facciamo sparire la prima
che e' vera),
D = false,

(Q F, P T, D F, L T),

in un albero di ricerca avrei
anche dovuto considerare i casi
 Q T, P F,.. ma sto facendo pruning
 per ottimizzare ispezionando i simboli
 puri,
 tolti i simboli puri si inizia a diramare,

** WalkSAT

Walk satisfyiability

P potrebbe essere 0.15 o 0.2,
con questa probabilita' fai una mossa casuale,
i flip sono i cambi di valore da T a F e viceversa,
si lavora sempre con assegnameneti completi,
si spostano poi i valori (come con
le N regine),
la variabile e' chiamata modello,
e' un assegnamento stocastico a tutti i simboli,
poi proviamo dando un upper bound al
n di passi di ricerca (max flip)
a vedere se dando un bound
trova la soluzione,
potrebbe anche non trovarla mai,
c'e' la tecnica del restart per permetterci di uscire
dai minimi locali,
faccio un po' di esplorazione poi se sono partito
male faccio un'altra ricerca,
l'algoritmo fa un solo run ma
potrebbe farne altri,
facendo tanti restart la probabilita'
di trovare la sol si alza,
se l'assegnamento corrente
soddisfa le clausole lo accetto,
altrimenti prendo una clausola che
non soddisfa il vincolo (es A or B falsa,
ne scelgo una delle due),
con una probabilita' bassa che imputo all'algoritmo
modifico scegliendo a caso uno dei due simboli
da T a F o viceversa,
se una clausola e' falsa tutti i letterali sono falsi,
quale scelgo da cambiare e' casuale,
altrimenti cambio il simbolo che,
cambiandogli valore, renderebbe il maggior
numero di clausole soddisfatte,
scelgo di cambiare A o B?
Se cambiando A ci sono altre clausole impattate
che diventano soddisfatte cambio lui,
se B ne ha molte di piu' che sarebbero
soddisfatte cambiandolo allora cambio lui,
A or B, A=F,B=F,
uno dei due deve cambiare valore da falso a vero,
quale dei due impatta meglio sulle altre formule?


20221102

WalkSAT -> ricerca locale, fa ricerca nello spazio
dei possibili assegnamenti booleani,
partendo da un assegnamento modifica le variabili.

SAT appartiene alla classe NP,

* Logica del primo ordine

1 -> KB !+ phi e KB & !phi

2 -> p1, p2, ..., pn  p1 & p2 & ... & pn => 0

Il primo metodo deve essere piu' potente perche'
e' completo,
il modus ponens e' un caso particolare
della risoluzione applicata a piu' step.

p1  !p1 | ...(alpha)..
----------------------
          alpha

esempio

p1  !p1 | q
-------------
       q

Tutte le formule si possono trasformare
in un insieme di clausole (CNF),

!p1 | !p2 | ... | q

equivale a

p1 & p2 & ... & pn => q

(trasformazione con il not davanti
all'antecedente...)

( p => q === !p | q)

nella base di conoscenza abbiamo anche p1 quindi
lo combiniamo:

poi abbiamo anche p2 e lo semplifichiamo,
poi p3, p4, ..., pn


(!p1) | (!p2) | ... | (!pn) | q  pn
------------------------------------
                  q

n risoluzioni unitarie con la clausola  pi (i da 1 a n)


Stiamo dimostrando che il concatenamento in avanti e indietro (che applica
il modus ponens) puo' derivare q nello stesso modo in cui lo puo' fare
la regola di risoluzione perche' se nella base
di conoscenza abbiamo p1, p2, ..., pn,
al posto dell'implicazione scriviamo !p1  | !p2 ... | q,
lo si deriva facendo il not dell'antecedente dell'implicazione,
per le leggi di demorgan il not diventa disgiunzione degli elementi
negati,
queste n+1 formule si scrivono con la disgiunzione + n formule atomiche,
applichiamo la risoluzione unitaria,
che vuole una clasuola unitaria e un'altra clausola non unaria (lunga n+1),
a ogni risoluzione diminuisco la lunghezza delle disgiunzioni di 1.


* Esercizi per l'esame

Completezza:
se c'e' soluzione l'alg la trova e se non c'e' l'alg se ne accorge
e dice che non c'e'.
L'alg in ampiezza e' teoricamente completo
ma nel caso di sol lunga non lo e' in pratica perche'
la memoria e' esponenziale, a meno che non ci
sia un fattore di diramazione di 1.1,
ma se gia' e' vicino a 2 non ce la facciamo, la memoria
occupata e' esponenziale.

La ricerca in ampiezza esce sempre dal ciclo,
pero' se non c'e' sol la terminazione non avviene,
la terminazione avviene per profondita' finita,
se la profondita' e' infinita non termina,
la completezza c'e' solo se l'algoritmo termina,
la profondita' massima finita fa in modo che
l'algoritmo termini,
se c'e' una soluzione lui la trova,
se c'e' un nodo che soddisfa il gol test
BFS lo trova,
se non c'e' una sol l'algoritmo non termina,
perche' l'albero ha profondita' infinita,
quindi non e' completo quando ci sono cicli
e non c'e' una soluzione,
se c'e' la sol e ci sono i cicli trova
la soluzione.
La ricerca in profondita' va su un percorso
e continua finche' non finisce quel percorso,
quindi potrebbe non fermarsi mai e non trovare
la sol quando ci sono cicli e c'e' la soluzione.
In DFS anche se c'e' la sol potrebbe non fermarsi
mai, mentre BFS se c'e' la sol si ferma sempre
(perche' la sol per definizione ha profondita' finita).

LRTA*.

Il pattern database disgiunti usa piu' euristiche
e richiede nel database che si siano le mosse in
particolare (da scontare) e non solo il numero,
il pattern dei database richiede una sola
euristica.

Per w a* la condizione e' anche che w=1.
wA* e' concepita per trovare piu' sol di
qualita' incrementale, avere subito
la sol migliore potrebbe richiedere
tempo, invece e' preferibile avere
subito una sol e poi incrementalmente
trovarne migliori,
- f
- w * h(n),
  h(n) ammissibile,
  w >= 1 (farlo minore di 1 non ha senso)

Inizialmente con w>1 vuol dire fare la ricerca
in modo piu' goloso, cerco di trovare una sol
piu' velocemente senza badare troppo al suo
costo,
ma sblianciandomi su h sto considerando di piu' h,
amplificandola potrebbe essere che non sia piu'
ammissibile,
potrei iniziare con w=1.5 (e posso sforare l'ammissibilita'),
trovo la sol e faccio ripartire l'alg con un
valore piu' piccolo,
siccome le sol sono w-ammissibili,
se abbasso sempre w trovo sol peggiorativa
ma sempre meno peggiorative,
fino ad arrivare a 1.05, 1.01, 1,
con w=1 sono tornato ad A*.

La consistenza non e' data dalla semplice ammissiblita',
la consistenza e' piu' forte dell'ammissibilita',
progettare un'euristica consistente e informativa
e' difficile e anche dimostrare che e' consistente,
se pero' ce l'ho il vantaggio e' che
arrivo all'ottimo con maggiore efficienza,
so che quando incontro uno stato una seconda volta posso
incontrarlo solo con un percorso peggiorativo.
MI basta memorizzare nella closed list gli stati che
ho gia' visitato e fare pruning,
se non c'e' consistenza devo sempre vedere se sto
riincontrando qualcosa con un percorso piu' corto (per poi
metterlo nella open),
altrimenti non lo rimetto nella open list.

Quando due euristiche sono ottimiste e' meglio
quella piu' grande, perche' si avvicina di piu'
alla verita'.
Con un'euristica peggiore la sol la trovi comunque
ma fai piu' sforzo.

Valore minimo dei nodi che superano f dopo
la prima iterazione (valore cut per iterative deepening A*).

tecnica di randomizzazione:
ordinare a caso i successori e prendere il primo
migliore (variante di hill climbing).

La ricerca bidirezionale non e' sempre applicabile,
innanzitutto devo conoscere lo stato goal,
la ricerca piu' safe nel bidirezionale e'
quella in ampiezza.

Focal search:

Se i domini sono discreti e finiti l'algoritmo AC3 termina,
se i domini sono continui l'algoritmo non termina.


20221107

** Semantica di F.O.L.

La logica del primo ordine e' piu' ricca, quindi
e' piu' lungo dare l'interpretazione per ogni insieme
di formule.

Insieme di formule = congiunzione di formule.

Ogni simbolo di predicato n-ario con n >= 0 viene
interpretato in d^n, ogni relazione e'
un sottoinsieme di n-uple,

Ci mancano da interpretare i somboli di variabile e funzione.

Una formula puo' essere vera o falsa, la verita' di una
formula atomica dipende da come e' interpretato il simbolo
proposizionale.
La formula atomica e' un predicato senza alcun argomento,
un predicato con uno o piu' termini e' n-ario,
una formula atomica e' il predicato uguaglianza
con due termini.

Amico di (Giovanni, Mario), n=2,
Mario -> costante da interpretare come una persona,
Giovanni -> ..
Deve esserci questa accoppiata nella relazione,

[Amico di] = {(oggetto_i, oggetto_j), (oggetto_k, oggetto_k)...},
[[Mario] deve essere un oggetto del dominio, es. oggetto_i,
l'interpretaizone di [Amico di(Mario, Giovanni)] richiede l'interpretazione
di Giovanni ( [Giovanni]), quella di [Mario], che sono
object)i e object_j,
e devo avere la coppia obj_i e obj_j all'interno di [Amico di],
se c'e' e' interpretata come VERO.

Le formule non atomiche? Vale lo stesso della logica proposizionale,
la semantica nella logica e' composizionale, dipende dalle componenti,
le componenti elementari le abbiamo fatte (predicati, funzioni,
variabili...),

I domini possono anche essere infiniti,
ma direttamente non possiamo trasformare
tutto in csp e fare backtracking come nella
semantica proposizionale,
l'unica cosa che possiamo fare e' procedure
di inferenza  sulle formule,
modificarle col modus ponens..

La logica proposizionale e' decidibile,
la logica del primo ordine NON lo e', non esiste
un algoritmo che dia sempre la risposta corretta,
ma per fortuna e' semidecidibile
(o si dimostra che qualcosa e' conseguenza logica
o non lo e'), se tutti e due si possono fare
allora e' decidibile, senno' no.
L'algoritmo esiste e ha un numero finito di passi,
L'algoritmo per decidere se una formula non e'
un teorema non finisce mai, le inferenze sono
infinite.
L'inferenza in alcuni esempi puo' andare avanti a derivare
formule diverse.



\forall stud \forall s \exists c_1, \exists c_2 supera(stud,c_1,s,v1) \and supera(stud,c_2,s,v_2) \and !(c_1=c_2) \and ..
\forall a_1,a_2 bocciato(stud,a_1) \and bpccoato(stud,a_2) => a_1 = a_2 (serve per dire che al massimo un appello \and

se  vogliamo dire che al msasimo sono 2 allora: a_1=a_2 or a_1=a_3 or a_2=a_3.

** Inferenza

Le variabili esistenziali non permettono
di usare gli algoritmo di inferenza,
quindi con un algoritmo di preprocessing si possono
sostituire a funzioni che hanno quantificatori universali che la precedono.
Ma al posto delle costanti NON posso mettere quantificatori universali.

*** Modus ponens generalizzato

Chiamato GMP, vuole n+1 formule come premessa,
nella logica proposizionale questa regola dice che n formule sono
atomiche e la n+1-esima e' fatta cosa',
senza or, senza not,...

Le formule atomiche dovranno avere solo variabili universali,
l'esiste si puo' comunque recuperare con il preprocessing
di prima (con le funzioni di Skolem).

King(John), Avido(John) \forall x King(x) \and Avido(x) => Malvagio(x),

si puo' rimuovere \forall perche' si sa gia' che se c'e' una variabile
allora e' universale (dopo la skolemizzazione),
l'inferenza per essere corretta deve essere
Malvagio(x)\Theta -> sostituisci(Malvagio(x), x=John),
\Theta = {x/John}

Malvagio(x) seguito da \Theta.


\forall x \forall y \forall z p1(x) \and p2(y) \and p3(f(x,y)) => Q(x,y,z)

p1(A), p2(f(A)), p3(k)  p1(x)\and p2(y) \and p3(f(x,y)) => Q(x,y,z)
------------------------------------------------------------------
                            ??????????


Primo fa match con il primo, seocndo col secondo..
devo fare l'inferenza che p1(x) valga anche per p1(A),
accumulo le sostituzioni che occorrono per fare il match:
\Theta = {x/A,y/f(A)}
p(f(x,y)) non lo posso sostituire,
alle variabili univerali posso sostituire cio' che voglio
io ma guido la sostituzione,

\forall k p(k)
---------------
  p(f(x,y))

Ho accumulato 3 sostituzioni di variabili universali
con un termine e adesso posso inferire
Q(x,y,z) ma non direttamente,
inferisco
Q(x,y,z)\Theta che e' {x/A,y/f(A),k/f(x,y)},
quindi inferisco Q(A,f(A),z).

20221110

Example knowledge base.

Algoritmo per applicare il forward chaining.

Prende una base di conoscenza in formule di horn
e una frase da dimostrare.
Se genero la formula alpha allora alpha e'
una conseguenza logica.

Il modus ponens deriva solo formule atomiche.
new e' linsieme di cio' che ho derivato.
per ogni implicazione che abbiamo (for each sentence r in KB)

deriviamo R(A,B).

mi chiedo se cio' che ho appena derivato e' alpha (in tal caso
termino), oppure e' quasi uguale ad alpha,
supponiamo che voglia dimostrare che
alpha sia uguale a R(A,Z),
il nostro Q' appena derivato e' R(A,B),
voglio dimostrare R(A,Z),
nel caso piu' semplice che avessi dovuto derivare
R(A,B) l'unify non genera fallimento,
pero' in caso diverso in alpha potrei
avere delle variabili,
se l'alpha e' R(A,Z) la risposta e' comunque
si' per due motivi:
nelle interrogazioni le variabili sono esistenziali,
non universali, nell'alpha se voglio dimostrare
qualcosa ho variabili esistenziali nella query
(e' nella kb che sono universali),
odbbiamo leggere l'interrogazione come
alpha = Esiste z tale che R(A,Z)?
rispondero' E z criminale(Z) al posto
che scrivere Criminale(West),
perche' siamo nella logica del primo ordine, possiamo
usare le variabili ma NON quelle universali,
si assume che siano esistenziali,
quando derivo R(A,B) faccio l'unificazione
e faccio il match (trova sostituzioni alle
variabili), z/B, sono uguali se pero'
sostituisci le variabili in questo modo,
phi != fail?
sono la stessa cosa se al posto della z ci metti B,
a questo punto l'algoritmo non restituisce semplicemente,
ma se e' true ritorna una sostituzione,
se l'interrogazione e' "C'e' un assassino?",
lui risponde "Si', e' lui),
dice non solo che la frase e' un teorema ma
fornisce anche la sostituzione,
e' un algoritmo proattivo,
ogni volta che si inferisce qualcosa di nuovo si mette
dentro a new,
aggiungo new alla base di conoscenza e ripeto,
perche' qualcosa che aggiungo adesso potrebbe far
scattare qualcosa che prima non poteva scattare,
se fallisce ritorna la sostituzione vuota.

Unify(R(A,B),R(A,B)) = {},
quando derivo qualcosa che ho gia' derivato
prima o che e' gia' nella base di conoscenza
non la aggiungo a new.
Renaming ->

Se nella base di conoscenza avessi
per ogni z R(A,Z)
e stessi inferendo per ogni y R(A,y)
starei inferendo la stessa cosa,
renaming non e' standardize,
se la formula atomica e' uguale a una
che gia' hai a meno del nome della
variabile allora stiamo dicendo
la stessa cosa,
due formule atomiche sono identiche se
hanno argomenti uguali oppure variabili
universali con nomi diversi.

Piace(x,GELATO) e Piace(y,GELATO) sono
la stessa cosa, sono l'una il renaming dell'altra,
se derivo qualcosa che e' il renaming di una
formula atomica che ho gia' non va considerata.

Usando questo algoritmo vediamo come
si generano sostituzioni.

Partendo dalla base di conoscenza contenente 4 formule
atomiche (American(West), Missile(M1), Owns(Nono,M1), Enemy(Nono,America),

(skolemizzazione per togliere x, era venuto fuori che m1 e' il missile
e che Nono possiede m1), 

Si tiene traccia delle sostituzioni fatte per applicare
il modus ponens e si applicano alla conseguenza
(nella relazione da enemy(nono,america) a hostile(nono) sono state
fatte sostituzioni),
per ogni x, enemy(x,america) => hostile(x),
il theta e' x sostituito da Nono,
derivo hostile(Nono),
formula atomica e implicazione sono il modus ponens,
derivo q a cui applico la sostituzione.

A and B => C \equiv !(A and B) or C
\equiv !A or !B or C

negazione formula atomica,
letterale negativo (la stessa cosa) e letterale positivo.

Se ammetto funzioni ho un numero infinito di formule atomiche.

Backward chaining example,
finisce quando abbiamo costruito il grafo al contrario,
applica il modus ponens al contrario.
In questo esempio ci chiediamo se esiste un criminale.
Posso rendere uguali degli elementi con una sostituzione
e dovro' ricordarmi di questo vincolo.

Missile(m1) matcha tramite la sostituzione y/m1,
si e' accumulata un'altra sostituzione dopo s/west,
quando sara' il turno di sells(x,y,z)
devo considerare al loro posto
west e m1,


20221115

Backward chaining,
di per se' non fa controlli sui loop,

Funzionano in modo completo solo con clausole
definite (forward e backward), ovvero con
le clausole di horn,
siamo con clausole definite senza funzioni
che definiscono il datalog,
non e' detto che questo sia fattibile, magari
mi servono formule piu' complesse come
una disgiunzione positiva A or B,
allora i sistemi per fare inferenza piu' potenti
si basano sulla risoluzione (gia' vista nella
logica proposizionale).

Per decidere se KB entails a:
- KB and a
- KB and not a
C'e' il caso in cui BB not entails a e KB not entails not a,
la logica del primo ordine e' semi-decidibile,
'semi' perche' se phi non e' conseguenza logica
di KB allora l'algoritmo di inferenza non e'
capace di dirci SEMPRE se phi e' conseguenza logica,
c'e' il caso in cui non termina.

Il metodo di risoluzione per rifiutazione ricava
la clausola vuota,
se not a e' conseguenza logica so che la dimostrazione
terminera' ma se not a non e' conseguenza logica potrebbe
andare avanti all'infinito,
siccome c'e' un terzo caso allora ce ne sono due che
potrebbero andare all'infinito e non so per quale dei
due motivi e' a causa della semidecidibilita'.
Non e' che non termina mai, ma esistono casi in cui non termina.
Se KB = {A or B} allora KB not entails a,
ma anche KB not entails not a,
ci sono casi a infiniti passi in cui non possiamo terminare.

f(x,B) non e' vero o falso, e' un individuo,
i termini di un predicato sono individui,
P(x,f(x,B),C):
not P(B,y,C),
B costante, y variabile, C costante,
notazione con lettere maiuscole costanti e lettere minuscole variabili,
le funzioni le riconosciamo perche' sono dentro ai predicati,
f non puo' essere un predicato,
e per essere una formula della logica del primo
ordine deve avere un forall davanti,
pero' non lo usa perche' tutte le variabili
sono universali, quelle esistenziali non ci sono piu'
(si rimuovono con la skilemizzazione),
facciamo l'unificazione per vedere se i predicati possono
essere uguali:
il simbolo di predicato e' uguale, il numero di termini
del predicato e' lo stesso,
allora procediamo coppia per coppia,
primo con primo, secondo con secondo e terzo con terzo:
nelle coppie ci possono essere costanti, variabili, funzioni.
il caso costante,costante richiede che le costanti
siano uguali,
il termine composto (funzione),
{x/B, y/f(B,B)},
le sostituzioni si propagano subito,
se x deve essere B sostituiamo subito,
quindi non arriveremo a z/x ma a z/B,
altrimenti se non lo faccio subito potrei
escrivere cose contradditorie.
Gli unici che non si unificano sono termine composto e costante,
quando c'e' una variabile si unifica sempre.

L'unificazione che abbiamo fatto rende uguali le formule,
ma puo' essere che due formule siano unificabili con sostituzioni diverse,
L'algoritmo unify trova la sostituzione piu' generale che vincola
di meno le variabili universali, quella che preferiamo.

Unification algorithm non chiede lo pseudocodice!

Ottimizzazione: evitiamo di sostituire
una variabile con un termine che contiene la variabile stessa,
non sostituiamo y con padre(y),
a una variabile possiamo sostituire quello che vogliamo
ma evitiamo queste ricorsioni o incorreremmo in un loop.
controllo che dentro a un termine composto non ci
sia la variabile con cui facciamo unification,
si chiama occur check.

** Teorema della correttezza e completezza della risoluzione

Conversione di una formula in CNF.
Prima si toglie il simbolo di implicazione,
Bisogna cambiare il nome a variabili
che hanno quantificatori diversi,
ogni quantificatore deve avere una variabile
diversa!
skolemizzazione (se non c'e' nessuna variabile universale
prima si introduce una nuova costante S_k,
l'importante e' che non sia gia' stata usata
prima,
se la variabile esistenziale e' preceduta da una universale
NON posso mettere la costante,
se forall x exists z Ama(x,z) stiamo
dicendo che tutti amano qualcuno, non che tutti
amano la stessa persona,
quindi sarebbe sbagliato dire
Ama(x,SK41),
perche' e' come se tutti amassero la stessa,
quando tolgo l'exists all'interno di un forall
sostituisco con una funzione di Skolem:
forall x Ama(x, f_{SK41}(x)).
Siccome non abbiamo piu' le esistenziali
(e neanche le universali)...

Il quantificatore piu' vicino ha la precedenza,

forall x (P(x) implies exists x Q(x))

forall x (not P(x) or exists x Q(x))

se avessi scritto senza parentesi

forall x P(x) implies exists x Q(x)

uso la seconda x in modo infelice,
e' equivalente a

forall x P(x) implies exists y Q(y)

ma meglio la seconda.

not forall x P(x) or exists x Q(x)

exists x not P(x) or exists x phi(x)

